<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>publications | Jean Paul Barddal</title>
    <meta name="author" content="Jean Paul Barddal" />
    <meta name="description" content="publications by categories in reversed chronological order. generated by jekyll-scholar." />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="http://0.0.0.0:8080/publications/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Jean </span>Paul Barddal</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              <li class="nav-item active">
                <a class="nav-link" href="/publications/">publications<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">publications</h1>
            <p class="post-description">publications by categories in reversed chronological order. generated by jekyll-scholar.</p>
          </header>

          <article>
            <!-- _pages/publications.md -->
<div class="publications">
  <h2 class="year">2023</h2>
  <ol class="bibliography"><li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">INFUS</abbr></div>

        <!-- Entry bib key -->
        <div id="INFUS_MARCOS_MONTEIRO:2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Exploring diversity in data complexity and classifier decision spaces for pool generation</div>
          <!-- Author -->
          <div class="author">
          

          Marcos Monteiro, Alceu S. Britto, Jean P. Barddal, Luiz S. Oliveira, and Robert Sabourin</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Information Fusion</em> --><div class="periodical">
            <em>Information Fusion</em> 2023
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/INFUS_MARCOS_MONTEIRO_2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper introduces a novel method for classifier pool generation in which a two-level strategy 
explores diversity in both data complexity and classifier decision spaces. The rationale is to induce pool members 
using data subsets representing subproblems with different difficulties while promoting diversity in classifiers’ decisions. 
Two possible variants of the proposed method with a focus on maximum dispersion and maximum accuracy are presented. 
These differ in the property used to define the best pool of classifiers provided by an optimization process. 
A robust experimental protocol encompassing 28 classification datasets shows that the proposed pool generation provided the 
best accuracy on 327 over 336 experiments (97.3%) when compared to well-known pool generation methods to provide multiple 
classifier systems with and without dynamic selection.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">INFUS_MARCOS_MONTEIRO:2022</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Exploring diversity in data complexity and classifier decision spaces for pool generation}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Information Fusion}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{89}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{567-587}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1566-2535}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.inffus.2022.09.001}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1566253522001336}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Monteiro, Marcos and Britto, Alceu S. and Barddal, Jean P. and Oliveira, Luiz S. and Sabourin, Robert}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Classifier pool generation, Diversity, Data complexity measures}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li></ol>

  <h2 class="year">2022</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ARXIV</abbr></div>

        <!-- Entry bib key -->
        <div id="https://doi.org/10.48550/arxiv.2210.03119" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Evaluating k-NN in the Classification of Data Streams with Concept Drift</div>
          <!-- Author -->
          <div class="author">
          

          Roberto Souto Maior Barros, Silas Garrido Teixeira de Carvalho Santos, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <div class="periodical">
            2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/arxiv_2210_03119.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data streams are often defined as large amounts of data flowing continuously at high speed. 
  Moreover, these data are likely subject to changes in data distribution, known as concept drift. 
  Given all the reasons mentioned above, learning from streams is often online and under restrictions of memory 
  consumption and run-time. Although many classification algorithms exist, most of the works published in the area 
  use Naive Bayes (NB) and Hoeffding Trees (HT) as base learners in their experiments. This article proposes an 
  in-depth evaluation of k-Nearest Neighbors (k-NN) as a candidate for classifying data streams subjected to concept drift. 
  It also analyses the complexity in time and the two main parameters of k-NN, i.e., the number of nearest neighbors used 
  for predictions (k), and window size (w). We compare different parameter values for k-NN and contrast it to NB and HT both 
  with and without a drift detector (RDDM) in many datasets. We formulated and answered 10 research questions which led to 
  the conclusion that k-NN is a worthy candidate for data stream classification, especially when the run-time constraint 
  is not too restrictive.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex">  <span class="c">doi = {10.48550/ARXIV.2210.03119},</span>
  <span class="c">author = {de Barros, Roberto Souto Maior and Santos, Silas Garrido Teixeira de Carvalho and Barddal, Jean Paul},</span>
  <span class="c">keywords = {Machine Learning (cs.LG), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},</span>
  <span class="c">title = {Evaluating k-NN in the Classification of Data Streams with Concept Drift},</span>
  <span class="c">publisher = {arXiv},</span>
  <span class="c">year = {2022},</span>
  <span class="c">copyright = {arXiv.org perpetual, non-exclusive license},</span>
<span class="c">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SMC</abbr></div>

        <!-- Entry bib key -->
        <div id="SMC_PATTERN_SPOTTING:2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Pattern Spotting and Image Retrieval in Historical Documents using Deep Hashing</div>
          <!-- Author -->
          <div class="author">
          

          Caio Silva Dias, Alceu Souza Britto Jr., <em>Jean Paul Barddal</em>, Laurent Heutte, and Alessandro Lameiras Koerich</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the IEEE Systems, Man, and Cybernetics Conference (IEEE SMC)</em> --><div class="periodical">
            <em>In Proceedings of the IEEE Systems, Man, and Cybernetics Conference (IEEE SMC)</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/SMC22_YEOJOHNSON.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper presents a deep learning approach for image retrieval
  and pattern spotting in digital collections of historical documents. First, a
  region proposal algorithm detects object candidates in the document page
  images. Next, deep learning models are used for feature extraction,
  considering two distinct variants, which provide either real-valued or binary
  code representations. Finally, candidate images are ranked by computing the
  feature similarity with a given input query. A robust experimental protocol
  evaluates the proposed approach considering each representation scheme
  (real-valued and binary code) on the DocExplore image database. The
  experimental results show that the proposed deep models compare favorably to
  the state-of-the-art image retrieval approaches for images of historical
  documents, outperforming other deep models by 2.56 percentage points using
  the same techniques for pattern spotting. Besides, the proposed approach also
  reduces the search time up to 200x, and the storage cost up to
  6,000x when compared to related works based on real-valued
  representations.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SMC_PATTERN_SPOTTING:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{da Silva Dias, Caio and de Souza Britto Jr., Alceu and Barddal, Jean Paul and Heutte, Laurent and Koerich, Alessandro Lameiras}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pattern Spotting and Image Retrieval in Historical Documents using Deep Hashing}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE Systems, Man, and Cybernetics Conference (IEEE SMC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SMC</abbr></div>

        <!-- Entry bib key -->
        <div id="SMC_YEOJOHNSON:2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Improving Data Stream Classification using Incremental Yeo-Johnson Power Transformation</div>
          <!-- Author -->
          <div class="author">
          

          Eduardo Tieppo, <em>Jean Paul Barddal</em>, and Julio Cesar Nievola</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the IEEE Systems, Man, and Cybernetics Conference (IEEE SMC)</em> --><div class="periodical">
            <em>In Proceedings of the IEEE Systems, Man, and Cybernetics Conference (IEEE SMC)</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/SMC22_YEOJOHNSON.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data transformation plays an essential role as a preprocessing
  step in learning models. Several classification techniques have premises about
  the underlying data distribution, such as normal distribution assumed in
  Bayesians classifiers. However, applying data transformation in a streaming
  setting requires processing an infinite and continuous flow of data. In this
  paper, we propose the Incremental Yeo-Johnson Power Transformation, a variant
  of the well-known batch Yeo-Johnson transformation that is tailored for
  streaming settings, i.e., it supports streaming data via statistical sampling
  and hypothesis testing. Experimental results show that our proposal achieves
  the same data normality as its batch counterpart. In addition, it improves
  the prediction performance of a data stream classifier based on Bayesian
  statistical models. Overall, learning models obtained 3 percentage points
  improvement.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SMC_YEOJOHNSON:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tieppo, Eduardo and Barddal, Jean Paul and Nievola, Julio Cesar}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Improving Data Stream Classification using Incremental Yeo-Johnson Power Transformation}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the IEEE Systems, Man, and Cybernetics Conference (IEEE SMC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ESANN</abbr></div>

        <!-- Entry bib key -->
        <div id="ESANN_KRUGER:2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Machine Learning Approach for School Dropout Prediction in Brazil</div>
          <!-- Author -->
          <div class="author">
          

          João Gabriel Corrêa Kruger, <em>Jean Paul Barddal</em>, and Alceu Souza Britto Jr.</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the 30th European Symposium on Artificial Neural Networks (ESANN)</em> --><div class="periodical">
            <em>In Proceedings of the 30th European Symposium on Artificial Neural Networks (ESANN)</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/ES2022-15.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>School dropout is a severe problem that impacts many
               socio-economic aspects, including inequality. Dropout prediction
               algorithms can help remediate this problem, although several past
               attempts in the literature did so using datasets with small
               numbers of students. This paper brings forward an experimental
               approach of machine learning for school dropout prediction in
               Brazilian schools. The data used for this study was first
               retrieved from the academic systems of a group of Brazilian
               private schools, which was later enriched with socio-economic
               data extracted from governmental sources. Using the dataset to
               train different types of classifiers, we obtained precision
               scores of up to 95.2% when predicting dropout at different year
               moments and educational stages, thus allowing schools to plan and
               apply retention strategies.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ESANN_KRUGER:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Kruger, João Gabriel Corrêa and Barddal, Jean Paul and de Souza Britto Jr., Alceu}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Machine Learning Approach for School Dropout Prediction in Brazil}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 30th European Symposium on Artificial Neural Networks (ESANN)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCNN</abbr></div>

        <!-- Entry bib key -->
        <div id="IJCNN_CHDS:2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Classifying Hierarchical Data Streams using Global Classifiers and Summarization Techniques</div>
          <!-- Author -->
          <div class="author">
          

          Eduardo Tieppo, <em>Jean Paul Barddal</em>, and Julio Cesar Nievola</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 2022 International Joint Conference on Neural Networks, IJCNN 2022,
               Padua, Italy, 2022</em> --><div class="periodical">
            <em>In 2022 International Joint Conference on Neural Networks, IJCNN 2022,
               Padua, Italy, 2022</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/ijcnn_chds_2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The hierarchical classification of data streams requires models
               capable of handling a class hierarchy and updating themselves
               whenever a new example arrives, within restrained processing time
               and memory consumption. Current state-of-the-art models store raw
               instances and handle the hierarchy locally, performing a high
               number of computations at every hierarchy level and with all,
               eventually redundant, data. This paper introduces Global
               k-Nearest Centroids (kNC) and Global Dribble, two novel methods
               for the hierarchical classification of data streams. Both methods
               use summarization techniques to represent data with constant
               computational resources usage and a global classification
               approach to process instances in less time when compared to local
               strategies. We compare both methods with a state-of-the-art
               local classifier, and the proposed methods achieved a higher
               number of correct predictions and process instances nearly
               twice as fast.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">IJCNN_CHDS:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tieppo, Eduardo and Barddal, Jean Paul and Nievola, Julio Cesar}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Classifying Hierarchical Data Streams using Global Classifiers and Summarization Techniques}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 International Joint Conference on Neural Networks, {IJCNN} 2022,
                 Padua, Italy, 2022}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCNN</abbr></div>

        <!-- Entry bib key -->
        <div id="IJCNN_FER:2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Evaluation of Self-taught Learning-based Representations for Facial Emotion Recognition</div>
          <!-- Author -->
          <div class="author">
          

          Bruna Delazeri, Leonardo Leon Veras, <em>Jean Paul Barddal</em>, Alessandro L. Koerich, and Alceu Souza Britto Jr.</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 2022 International Joint Conference on Neural Networks, IJCNN 2022,
               Padua, Italy, 2022</em> --><div class="periodical">
            <em>In 2022 International Joint Conference on Neural Networks, IJCNN 2022,
               Padua, Italy, 2022</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/ijcnn_fer_2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This work describes different strategies to generate unsupervised
               representations obtained through the concept of self-taught
               learning for facial emotion recognition (FER). The idea is to
               create complementary representations promoting diversity by
               varying the autoencoders’ initialization,  architecture, and
               training data. SVM, Bagging, Random Forest, and a dynamic
               ensemble selection method are evaluated as final classification
               methods. Experimental results on JAFFE and Cohn-Kanade datasets
               using a leave-one-subject-out protocol show that FER methods
               based on the proposed diverse representations compare favorably
               against state-of-the-art approaches that also explore unsupervised
               feature learning.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">IJCNN_FER:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Delazeri, Bruna and Veras, Leonardo Leon and Barddal, Jean Paul and Koerich, Alessandro L. and de Souza Britto Jr., Alceu}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Evaluation of Self-taught Learning-based Representations for Facial Emotion Recognition}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 International Joint Conference on Neural Networks, {IJCNN} 2022,
                 Padua, Italy, 2022}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCNN</abbr></div>

        <!-- Entry bib key -->
        <div id="DIFOT_IJCNN:2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Assessing Batch and Online Learning for Delivery in Full and On Time Predictions</div>
          <!-- Author -->
          <div class="author">
          

          Adriano Alves Lima, Márcio Venâncio Batista, <em>Jean Paul Barddal</em>, Danilo Sipoli Sanches, and Luiz Eduardo Soares Oliveira</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 2022 International Joint Conference on Neural Networks, IJCNN 2022,
               Padua, Italy, 2022</em> --><div class="periodical">
            <em>In 2022 International Joint Conference on Neural Networks, IJCNN 2022,
               Padua, Italy, 2022</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/ijcnn_difot_2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Improving results by optimizing process execution is one objective
               of major companies. For these corporations, the main point for
               achieving better results is the good maintenance of supply chain
               management. The most important supply chain metric is Delivery
               in Full and On Time (DIFOT). DIFOT measures how well a supply
               chain delivers value to the customer. In this work, we bring
               forward an analysis of DIFOT prediction from large Brazilian food
               company. More specifically, we compare a batch and online
               learning algorithm for DIFOT prediction and depict why the
               latter is suitable for this problem. Furthermore, we report a
               feature drift analysis to identify whether there are considerable
               shifts along with the dataset timespan. As a byproduct of this
               research, we make the dataset used in this analysis publicly
               available for future research in DIFOT prediction.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DIFOT_IJCNN:2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{de Lima, Adriano Alves and Batista, Márcio Venâncio and Barddal, Jean Paul and Sanches, Danilo Sipoli and de Oliveira, Luiz Eduardo Soares}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Assessing Batch and Online Learning for Delivery in Full and On Time Predictions}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 International Joint Conference on Neural Networks, {IJCNN} 2022,
                 Padua, Italy, 2022}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ESWA</abbr></div>

        <!-- Entry bib key -->
        <div id="ESWA_PKLOT_SURVEY:2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Systematic Review on Computer Vision-Based Parking Lot Management Applied on Public Datasets</div>
          <!-- Author -->
          <div class="author">
          

          Paulo Ricardo Lisboa Almeida, Jeovane Honório Alves, Rafael Stubs Parpinelli, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Expert Systems with Applications</em> --><div class="periodical">
            <em>Expert Systems with Applications</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/draft_pklot_survey2022.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Computer vision-based parking lot management methods have been extensively
  researched upon owing to their flexibility and cost-effectiveness. To evaluate such
  methods authors often employ publicly available parking lot image datasets. In this
  study, we surveyed and compared robust publicly available image datasets specifically
  crafted to test computer vision-based methods for parking lot management approaches and
  consequently present a systematic and comprehensive review of existing works that employ
  such datasets. The literature review identified relevant gaps that require further research,
  such as the requirement of dataset-independent approaches and methods suitable for autonomous
  detection of position of parking spaces. In addition, we have noticed that several important
  factors such as the presence of the same cars across consecutive images, have been neglected
  in most studies, thereby rendering unrealistic assessment protocols. Furthermore, the analysis
  of the datasets also revealed that certain features that should be present when developing new
  benchmarks, such as the availability of video sequences and images taken in more diverse conditions,
  including nighttime and snow, have not been incorporated.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ESWA_PKLOT_SURVEY:2022</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{de Almeida, Paulo Ricardo Lisboa and Alves, Jeovane Honório and Parpinelli, Rafael Stubs and Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Systematic Review on Computer Vision-Based Parking Lot Management Applied on Public Datasets}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Expert Systems with Applications}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICAART</abbr></div>

        <!-- Entry bib key -->
        <div id="TIEPPO_KNC_DRIBBLE" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Univariate Time Series Prediction Using Data Stream Mining Algorithms and Temporal Dependence</div>
          <!-- Author -->
          <div class="author">
          

          Marcos Alberto Mochinski, <em>Jean Paul Barddal</em>, and Fabricio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of International Conference on Agents and Artificial Intelligence,
               ICAART 2022</em> --><div class="periodical">
            <em>In Proceedings of International Conference on Agents and Artificial Intelligence,
               ICAART 2022</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/ICAART_2022_165.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this paper, we present an exploratory study conducted to
  evaluate the impact of temporal dependence modeling on time series forecasting
  with Data Stream Mining (DSM) techniques. DSM algorithms have been used
  successfully in many domains that exhibit continuous generation of
  non-stationary data. However, the use of DSM in time series is rare since they
   usually are univariate and exhibit strong temporal dependence.
  This is the main motivation for this work, such that this study mitigates such
  gap by presenting a univariate time series prediction method based on AdaGrad
  (a DSM algorithm), Auto.Arima (a statistical method) and features extracted
  from adjusted autocorrelation function (ACF) coefficients. The proposed method
  uses adjusted ACF features to convert the original series observations into
  multivariate data, executes the fitting process using the DSM and the
  statistical algorithm, and combines the AdaGrad’s and Auto.Arima’s forecasts
  to establish the final predictions for each time series. Experiments conducted
  with five datasets containing 141,558 time series resulted in up to 12.429%
  improvements in sMAPE (Symmetric Mean Average Percentage Error) error rates
  when compared to Auto.Arima. The results depict that combining DSM with ACF
  features and statistical time series methods is a suitable approach for
  univariate forecasting.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TIEPPO_KNC_DRIBBLE</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mochinski, Marcos Alberto and Barddal, Jean Paul and Enembreck, Fabricio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Univariate Time Series Prediction Using Data Stream Mining Algorithms and Temporal Dependence}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of International Conference on Agents and Artificial Intelligence,
                 {ICAART} 2022}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SAC</abbr></div>

        <!-- Entry bib key -->
        <div id="TIEPPO_KNC_DRIBBLF" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Automatic Disease Vector Mosquitoes Identification via Hierarchical Data Stream Classification</div>
          <!-- Author -->
          <div class="author">
          

          Eduardo Tieppo, <em>Jean Paul Barddal</em>, and Julio Cesar Nievola</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the Annual ACM Symposium on Applied Computing,
               SAC 2022</em> --><div class="periodical">
            <em>In Proceedings of the Annual ACM Symposium on Applied Computing,
               SAC 2022</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/SAC_2022_KNC_DRIBBLE.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Vector-borne diseases (VBDs), such as Dengue or Malaria, are one of the main concerns of public health agencies and governments.
  These diseases are mainly spread by mosquitoes acting as vectors by transmitting infected blood between humans.
  Machine learning can be used to design and improve control strategies of VBDs by providing models able to recognize disease vector mosquitoes and automatically capture or kill harmful species.
  The automatic identification of disease vector mosquitoes was not yet addressed concerning the hierarchical classification of data streams.
  Thus, reliable information has not been used to improve learning models, such as mosquitoes’ hierarchical taxonomy.
  In this study, we propose a framework for the automatic identification of disease vector mosquitoes in the context of the hierarchical classification of data streams area.
  To this end, we propose a hierarchical adaptation of a disease vector mosquitoes’ dataset to include their taxonomy and introduce kNC and Dribble, two novel classification methods fitted to hierarchical data streams representing the mosquitoes.
  Results depicted that our framework, using summarization techniques, achieves significantly better prediction and processing speed rates when compared to existing state-of-the-art models.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TIEPPO_KNC_DRIBBLF</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tieppo, Eduardo and Barddal, Jean Paul and Nievola, Julio Cesar}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Automatic Disease Vector Mosquitoes Identification via Hierarchical Data Stream Classification}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Annual {ACM} Symposium on Applied Computing,
                 {SAC} 2022}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACM CSUR</abbr></div>

        <!-- Entry bib key -->
        <div id="SURVEY_PROCESS_MINING_DRIFT:2022" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Survey on Concept Drift in Process Mining</div>
          <!-- Author -->
          <div class="author">
          

          Denise Maria Vecino Sato, Sheila Cristiana Freitas, <em>Jean Paul Barddal</em>, and Edson Emilio Scalabrin</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>ACM Computing Surveys</em> --><div class="periodical">
            <em>ACM Computing Surveys</em> 2022
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/sato2021.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Concept drift in process mining (PM) is a challenge as classical
  methods assume processes are in a steady-state, i.e., events share the same
  process version. We conducted a systematic literature review on the
  intersection of these areas, and thus, we review concept drift in process
  mining and bring forward a taxonomy of existing techniques for drift
  detection and online process mining for evolving environments. Existing works
  depict that (i) PM still primarily focuses on offline analysis, and (ii) the
  assessment of concept drift techniques in processes is cumbersome due to the
  lack of common evaluation protocol, datasets, and metrics.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SURVEY_PROCESS_MINING_DRIFT:2022</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sato, Denise Maria Vecino and de Freitas, Sheila Cristiana and Barddal, Jean Paul and Scalabrin, Edson Emilio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Survey on Concept Drift in Process Mining}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Computing Surveys}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2021</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICPM</abbr></div>

        <!-- Entry bib key -->
        <div id="SATO_ICPM:2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Interactive Process Drift Detection: a framework for visual analysis of process drifts</div>
          <!-- Author -->
          <div class="author">
          

          Denise Maria Vecino Sato, Rafaela Mantovani Fontana, <em>Jean Paul Barddal</em>, and Edson Emilio Scalabrin</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In International Conference on Process Mining (ICPM) - Demo track</em> --><div class="periodical">
            <em>In International Conference on Process Mining (ICPM) - Demo track</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/L-Interactive-Process-Drift-Detection-A-Framework-for-Visual-Analysis-of-Process-Drifts.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Interactive Process Drift Detection (IPDD) is a framework for visual analysis of
  process drifts. A process drift indicates a change in the process model occurred at some point
  in time. IPDD approach firstly generates process models for subparts of the event log using a
  sliding window approach. Then, IPDD detects the drifts by evaluating similarity metrics calculated
  between adjacent process models; a difference in some of the metrics indicates a drift. The current
  implementation of IPDD generates the process models using the directly-follows graph and applies two
  similarity metrics: nodes and edges similarity. The user interface shows the drifts in the process
  models over time, allowing the user to visually understand the model changes. Also, the user can easily
  change the hyperparameters for the drift analysis and verify the results on the interface. The user
  interface of IPDD also allows the user to evaluate the detected drifts by calculating the F-score metrics,
  which is useful when using artificial datasets. The underlying idea is to ease the choice of a "good"
  value for the hyperparameter configuration, which is critical for almost any drift detection mechanism.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SATO_ICPM:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sato, Denise Maria Vecino and Fontana, Rafaela Mantovani and Barddal, Jean Paul and Scalabrin, Edson Emilio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Interactive Process Drift Detection: a framework for visual analysis of process drifts}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Process Mining (ICPM) - Demo track}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">AIRE</abbr></div>

        <!-- Entry bib key -->
        <div id="TIEPPO_SLR:2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Hierarchical classification of data streams: a systematic literature review</div>
          <!-- Author -->
          <div class="author">
          

          Eduardo Tieppo, Roger Robson Santos, <em>Jean Paul Barddal</em>, and Júlio Cesar Nievola</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Artificial Intelligence Review</em> --><div class="periodical">
            <em>Artificial Intelligence Review</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/tieppo_survey.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The classification task usually works with flat and batch learners,
  assuming problems as stationary and without relations between class labels.
  Nevertheless, several real-world problems do not assume these premises, i.e.,
  data have labels organized hierarchically and are made available in streaming
  fashion, meaning that their behavior can drift over time. Existing studies on
  hierarchical classification do not consider data streams as input of their process,
  and thus, data is assumed as stationary and handled through batch learners. The same
  can be said about works on streaming data, as the hierarchical classification is
  overlooked. Studies concerning each area individually are promising, yet, do not
  tackle their intersection. This study analyzes the main characteristics of the
  state-of-the-art works on hierarchical classification for streaming data concerning
  five aspects: (i) problems tackled, (ii) datasets, (iii) algorithms, (iv) evaluation
  metrics, and (v) research gaps in the area. We performed a systematic literature
  review of primary studies and retrieved 3,722 papers, of which 42 were identified
  as relevant and used to answer the aforementioned research questions.
  We found that the problems handled by hierarchical classification of data streams
  include mainly classification of images, human activities, texts, and audio; the
  datasets are mostly created or synthetic data; the algorithms and evaluation metrics
  are well-known techniques or based on those; and research gaps are related to dynamic
  context, data complexity, and computational resources constraints.
  We also provide implications for future research and experiments to consider common
  characteristics shared amongst hierarchical classification and data stream classification.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">TIEPPO_SLR:2021</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tieppo, Eduardo and dos Santos, Roger Robson and Barddal, Jean Paul and Nievola, Júlio Cesar}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hierarchical classification of data streams: a systematic literature review}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Artificial Intelligence Review}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">BRACIS</abbr></div>

        <!-- Entry bib key -->
        <div id="TIEPPO_BRACIS:2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Classifying Potentially Unbounded Hierarchical Data Streams with Incremental Gaussian Naive Bayes</div>
          <!-- Author -->
          <div class="author">
          

          Eduardo Tieppo, Julio Cesar Nievola, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Brazilian Conference on Intelligent System (BRACIS)</em> --><div class="periodical">
            <em>In Brazilian Conference on Intelligent System (BRACIS)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/bracis_tieppo.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Hierarchical Classification of Data Streams inherits the properties
  and constraints of Hierarchical Classification and Data Stream Classification
  areas concomitantly. Therefore, it requires novel approaches that (i) can handle
  class hierarchies, (ii) can be updated over time, and (iii) are computationally
  light-weighted regarding processing time and memory usage. In this study, we
  propose the \emphGaussian Naive Bayes for Hierarchical Data Streams (GNB-hDS)
  method: an incremental Gaussian Naive Bayes for classifying potentially unbounded
  hierarchical data streams. The GNB-hDS method uses statistical summaries of the
  data stream instead of storing actual instances. These statistical summaries allow
  more efficient data storage, maintain constant computational time and memory, and
  calculate the probability of an instance belonging to a specific class via the
  Bayes’ Theorem. We compare our method against a technique that stores raw instances,
  and results show that our method obtains equivalent prediction rates while being
  statistically faster.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TIEPPO_BRACIS:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tieppo, Eduardo and Nievola, Julio Cesar and Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Classifying Potentially Unbounded Hierarchical Data Streams with Incremental Gaussian Naive Bayes}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Brazilian Conference on Intelligent System (BRACIS)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SMC</abbr></div>

        <!-- Entry bib key -->
        <div id="TIEPPO_SMC:2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Adaptive Global k-Nearest Neighbors for Hierarchical Classification of Data Streams</div>
          <!-- Author -->
          <div class="author">
          

          Eduardo Tieppo, <em>Jean Paul Barddal</em>, and Julio Cesar Nievola</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In IEEE Conference on Systems, Man, and Cybernetics (SMC)</em> --><div class="periodical">
            <em>In IEEE Conference on Systems, Man, and Cybernetics (SMC)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/smc_globalknn.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data stream classification differs from batch learning classification methods as data is made available sequentially and may drift over time. Therefore, data stream classification can be simultaneous to all other kinds of classification problems, and it has been revisiting many aspects related to classification in the last years. So far, hierarchical classification was weakly addressed in streaming scenarios despite being a well-established research topic. In this paper, we propose the adaptive global k-Nearest Neighbors for hierarchical classification of data streams (Global kNN-hDS). Our proposal is able to classify hierarchical data streams using a constrained memory buffer and following a global approach. We compare our method against a local kNN also tailored for streaming scenarios, and results show that our method obtains competitive prediction rates while being statistically faster.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TIEPPO_SMC:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tieppo, Eduardo and Barddal, Jean Paul and Nievola, Julio Cesar}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adaptive Global k-Nearest Neighbors for Hierarchical Classification of Data Streams}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Conference on Systems, Man, and Cybernetics (SMC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCNN</abbr></div>

        <!-- Entry bib key -->
        <div id="LUCCA1_IJCNN:2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Dynamically Selected Ensemble for Data Stream Classification</div>
          <!-- Author -->
          <div class="author">
          

          Lucca Portes Cavalheiro, <em>Jean Paul Barddal</em>, Alceu Souza Britto Jr., and Laurent Heutte</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In International Joint Conference on Neural Networks (IJCNN)</em> --><div class="periodical">
            <em>In International Joint Conference on Neural Networks (IJCNN)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/ddcs.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Mining data streams is a hot topic in the machine learning (ML) community.
  In addition to learning and updating accurate models over time, these techniques must
  respect constraints that are not necessarily as strong in batch mode, such as time processing
  and memory consumption efficiency. A successful family of techniques in batch ML is dynamic
  classifier selection (DCS). However, these are roughly overlooked in data stream mining.
  In this paper, we propose a novel dynamic classifier selection framework for data streams
  called Double Dynamic Classifier Selection (DDCS). We compare DDCS against state-of-art methods
  for mining data streams in both synthetic and real-world datasets. Results depict that DDCS not
  only outperforms the state-of-art ensemble methods for data stream classification in terms of
  accuracy but is also significantly more efficient in terms of processing time and memory consumption.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">LUCCA1_IJCNN:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cavalheiro, Lucca Portes and Barddal, Jean Paul and de Souza Britto Jr., Alceu and Heutte, Laurent}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Dynamically Selected Ensemble for Data Stream Classification}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Neural Networks (IJCNN)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCNN</abbr></div>

        <!-- Entry bib key -->
        <div id="LUCCA2_IJCNN:2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Towards the Overcome of Performance Pitfalls in Data Stream Mining Tools</div>
          <!-- Author -->
          <div class="author">
          

          Lucca Portes Cavalheiro, Marco Antonio Alves Zanata, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In International Joint Conference on Neural Networks (IJCNN)</em> --><div class="periodical">
            <em>In International Joint Conference on Neural Networks (IJCNN)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/lucca_pitfalls.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data stream mining is an essential task in today’s scientific community.
  It allows machine learning models to be updated over time as new data becomes available.
  Three pillars should be accounted for when selecting an appropriate algorithm for data stream mining: accuracy, processing time, and memory consumption.
  To develop and assess machine learning models in streaming scenarios, different tools have been developed, where the Massive Online Analysis, written in Java, and scikit-multiflow, written in Python, are in the spotlight.
  Despite the ease of use of both tools, neither are focused on performance, which puts in jeopardy the usage of the computational resources.
  In this paper, we show that with the right tools, Python libraries reach performance comparable to C/C++.
  More specifically, we show how optimized implementations in scikit-multiflow using low-level languages, i.e., C++, C++ with Intel Intrinsics, and Rust; with bindings to Python vastly overcome existing tools in computational resources usage while keeping predictive performance intact.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">LUCCA2_IJCNN:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Cavalheiro, Lucca Portes and Zanata, Marco Antonio Alves and Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards the Overcome of Performance Pitfalls in Data Stream Mining Tools}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Neural Networks (IJCNN)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICAISC</abbr></div>

        <!-- Entry bib key -->
        <div id="DENISE:2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Interactive Process Drift Detection Framework</div>
          <!-- Author -->
          <div class="author">
          

          Denise Maria Vecino Sato, <em>Jean Paul Barddal</em>, and Edson Emilio Scalabrin</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In International Conference on Artificial Intelligence and Soft Computing (ICAISC)</em> --><div class="periodical">
            <em>In International Conference on Artificial Intelligence and Soft Computing (ICAISC)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/ipdd.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper presents a novel tool for detecting drifts in process models.
  The tool targets the challenge of defining the better parameter configuration for detecting
  drifts by providing an interactive user interface. Using this interface, the user can quickly
  change the parameters and verify how the process evolved. The process evolution is presented
  in a timeline of process models, simulating a “replay” of models over time. One instantiation
  of the framework was implemented using a fixed-size sliding window, discovering process maps
  using directly-follows graphs (DFGs), and calculating nodes and edges similarities. This instantiation
  was evaluated using a benchmarking dataset of simple and complex drift patterns. The tool correctly
  detected 17 from the 18 change patterns, thus confirming its potential when an adequate window size
  is set. The user interface shows that replaying the process models provides a visual understanding of
  the changing process. The concept drift is explained by the similarity metrics’ differences, thus
  allowing drift localization. </p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DENISE:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sato, Denise Maria Vecino and Barddal, Jean Paul and Scalabrin, Edson Emilio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Interactive Process Drift Detection Framework}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Artificial Intelligence and Soft Computing (ICAISC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ESWA</abbr></div>

        <!-- Entry bib key -->
        <div id="ESWA_SUPERMARKET:2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A case study of batch and incremental recommender systems in supermarket data under concept drifts and cold start</div>
          <!-- Author -->
          <div class="author">
          

          Antônio David Viniski, <em>Jean Paul Barddal</em>, Alceu Souza Britto Jr., Fabricio Enembreck, and Humberto Vinicius Aparecido Campos</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Expert Systems with Applications</em> --><div class="periodical">
            <em>Expert Systems with Applications</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/case_study_recsys.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Recommender systems uncover relationships between users and items, thus allowing personalized recommendations.
            Nonetheless, users’ preferences may change over time, the so-called concept drifts; or new users and items may appear,
            making the recommender system unable to accurately map the relationship between users and items due to the cold start problem.
            Consequently, concept drift and cold start are challenges that downgrade the recommender system’s predictive performance.
            This paper assesses existing approaches for collaborative-filtering recommender systems over a real supermarket dataset that
            exhibits both of the issues mentioned above.
            For this purpose, our comparative analysis encompasses batch and streaming learning approaches.
            As a result, we can observe that streaming-based models achieve better recommendation rates since these are tailored to fit the concept drift.
            More specifically, the predictive performance of streaming-based recommendations increases by up to 21% over those provided by batch methods.
            The supermarket dataset used in experimentation is also made publicly available for future studies and recommender systems comparisons.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ESWA_SUPERMARKET:2021</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Elsevier}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Viniski, Ant\^{o}nio David and Barddal, Jean Paul and de Souza Britto Jr., Alceu and Enembreck, Fabricio and de Campos, Humberto Vinicius Aparecido}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A case study of batch and incremental recommender systems in supermarket data under concept drifts and cold start}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Expert Systems with Applications}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">PAKDD</abbr></div>

        <!-- Entry bib key -->
        <div id="BARDDAL_PAKDD:2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">UKIRF: An Item Rejection Framework for Improving Negative Items Sampling in One-Class Collaborative Filtering</div>
          <!-- Author -->
          <div class="author">
          

          Antônio David Viniski, <em>Jean Paul Barddal</em>, and Alceu Souza Britto Jr.</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)</em> --><div class="periodical">
            <em>In Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/ukirf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Collaborative Filtering (CF) is one of the most successful techniques in recommender systems.
               Most CF scenarios depict positive-only implicit feedback, which means that negative feedback is unavailable.
               Therefore, One-Class Collaborative Filtering (OCCF) techniques have been tailored to tackling these scenarios.
               Nonetheless, several OCCF models still require negative observations during training, and thus, a popular approach
               is to consider randomly selected unknown relationships as negative.
               In this work, we bring forward a novel approach for selecting negative items called Unknown Item Rejection Framework (UKIRF).
               More specifically, we instantiate UKIRF using similarity approaches, i.e., TF-IDF and Cosine, to reject items that are similar
               to those a user interacted with. We apply UKIRF to different OCCF models in different datasets and show that it improves the
               recall rates up to 24% when compared to random sampling. </p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BARDDAL_PAKDD:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Viniski, Antônio David and Barddal, Jean Paul and de Souza Britto Jr., Alceu}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{UKIRF: An Item Rejection Framework for Improving Negative Items Sampling in One-Class Collaborative Filtering}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICPR</abbr></div>

        <!-- Entry bib key -->
        <div id="BARDDAL_ICPR:2021" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Classifier Pool Generation based on a Two-level Diversity Approach</div>
          <!-- Author -->
          <div class="author">
          

          Marcos Monteiro, Alceu Souza Britto Jr, <em>Jean Paul Barddal</em>, Luiz Soares Oliveira, and Robert Sabourin</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In International Conference on Pattern Recognition (ICPR)</em> --><div class="periodical">
            <em>In International Conference on Pattern Recognition (ICPR)</em> 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/classifier_pool_two_level.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper describes a classifier pool generation method
  guided by the diversity estimated on the data complexity and classifier
  decisions. First, the behavior of complexity measures is assessed by
  considering several subsamples of the dataset. The complexity measures
  with high variability across the subsamples are selected for posterior
  pool adaptation, where an evolutionary algorithm optimizes diversity in
  both complexity and decision spaces. A robust experimental protocol with
  28 datasets and 20 replications is used to evaluate the proposed method.
  Results show significant accuracy improvements in 69.4% of the experiments
  when Dynamic Classifier Selection and Dynamic Ensemble Selection methods
  are applied.  </p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BARDDAL_ICPR:2021</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Monteiro, Marcos and de Souza Britto Jr, Alceu and Barddal, Jean Paul and Oliveira, Luiz Soares and Sabourin, Robert}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Classifier Pool Generation based on a Two-level Diversity Approach}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Conference on Pattern Recognition (ICPR)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2020</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SMC</abbr></div>

        <!-- Entry bib key -->
        <div id="BARDDAL_SMC1_2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Combining Slow and Fast Learning for Improved Credit Scoring  </div>
          <!-- Author -->
          <div class="author">
          

          Lucas Loezer Jean Paul Barddal, and Riccardo Lanzuolo</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em> --><div class="periodical">
            <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/combined_slow_fast_credit_scoring.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The financial credibility of a person is a relevant factor
to determine whether a loan should be approved or not, and
it is quantified by a credit score, which is computed using
past performance on debt obligations, profiling, and other
data available.
Credit scoring becomes even a hotter topic in emerging
countries, as interest rates and customer behavior swiftly
vary, given the economic (in)stability of the country and
as fintechs are chasing robust solutions for improved
credit scoring solutions.
Batch machine learning is often deployed for credit
scoring, yet, they are tailored for static scenarios, i.e.,
they are not prepared to swiftly detect and adapt to
changes in customer behavior, thus leading to slow recovery
in such scenarios.
In this paper, we bring forward an analysis on how batch
machine learning can be combined with data stream mining
techniques, thus leading to better recognition rates in
credit scoring scenarios.
We analyze three different real-world datasets from
Brazilian financial institutions, whilst keeping their
secrecy preserved, and show how batch and stream learning
can be combined towards improved credit scoring systems, as
well as highlighting relevant gaps that still require
attention.  </p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BARDDAL_SMC1_2020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jean Paul Barddal, Fabricio Enembreck, Lucas Loezer and Lanzuolo, Riccardo}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Combining Slow and Fast Learning for Improved Credit Scoring  }</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SMC</abbr></div>

        <!-- Entry bib key -->
        <div id="BARDDAL_SMC2_2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Naïve Approaches to Deal with Concept Drifts </div>
          <!-- Author -->
          <div class="author">
          

          Alceu Souza Britto Jr Almeida, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em> --><div class="periodical">
            <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/naive_approaches_concept_drift.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>A common problem in machine learning is to find
representative real-world problems to put the methods to
test. When developing approaches to deal with concept
drifts, some datasets such as the Forest Covertype and
Nebraska Weather are a common choice for testing. We argue
that some well-known real-world concept drift datasets
present a high serial dependence in the target class and
may have only minor changes. With this in mind, we propose
the use of naïve methods that should be used for
comparison with methods that deal with concept drifts. The
experimental results using six real-world well-known
concept drift datasets show that the naïve
approaches can be better than some methods to deal with
possible concept drifts in datasets such as the Forest
Covertype, Electricity, and Nebraska Weather. These results
suggest that some widely used datasets may be trivial from
the concept drift standpoint, and thus, should be avoided
or at least the results should be compared with the
proposed naïve methods.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BARDDAL_SMC2_2020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Paulo Ricardo Lisboa de Almeida, Luiz Oliveira, Alceu Souza Britto Jr and Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Naïve Approaches to Deal with Concept Drifts }</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SMC</abbr></div>

        <!-- Entry bib key -->
        <div id="BARDDAL_SMC3_2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Improving Multiple Time Series Forecasting with Data Stream Mining Algorithms  </div>
          <!-- Author -->
          <div class="author">
          

          Jean Paul Barddal Marcos Alberto Mochinski, and Fabricio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em> --><div class="periodical">
            <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/multiple_time_series.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This paper proposes a hybrid ensemble learning approach
that combines statistical and data stream mining algorithms
to obtain better forecasting performance in multiple time
series prediction problems. Although some multiple time
series algorithms perform surprisingly well in a variety of
domains, it is well-known that no one is dominant for every
existent domain. Therefore, we developed a meta-technique
based on data stream mining and static ensemble selection
strategy and evaluated its forecasting goodness-of-fit in
time series datasets from M3 and M4 competitions. After
training different regression models, we show how the
combination of auto.arima and AdaGrad lead to improved
forecasting rates, thus surpassing the results of
state-of-art algorithms.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BARDDAL_SMC3_2020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Marcos Alberto Mochinski, Jean Paul Barddal and Enembreck, Fabricio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Improving Multiple Time Series Forecasting with Data Stream Mining Algorithms  }</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SMC</abbr></div>

        <!-- Entry bib key -->
        <div id="BARDDAL_SMC4_2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">ADADRIFT: An Adaptive Learning Technique for Long-History Stream-Based Recommender Systems  </div>
          <!-- Author -->
          <div class="author">
          

          Fabricio Enembreck Eduardo Ferreira José, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em> --><div class="periodical">
            <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/adadrift.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Adaptive recommender systems are increasingly showing their
importance as profiling is a dynamic problem. Their goal is
to update recommendation models as new interactions take
place, thus swiftly adapting to drifts in the user’s
behavior and desires, and item’s audience. However,
existing recommendation algorithms usually do not perform
well during drifts, as they take long to adapt to changes,
or these updates are suboptimal since they account for all
profiles’ preferences equally, which is often untrue as
each individual and its changes are unique. In this paper,
we propose the ADADRIFT algorithm to deal with user and
item-based drifts in adaptive recommender systems using
personalized learning rates based on profile statistics.
The experiments using stream-based recommender systems
(ISGD and BRISMF) across four different datasets show that
ADADRIFT surpasses ADADELTA with significant improvements
in recommendation rates. The best results appear when the
data streams have a long history of the users’ or items’
interactions and drifts become noticeable. The
experimentation in this work highlight the importance of
handling drifts in recommender systems. </p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BARDDAL_SMC4_2020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Eduardo Ferreira José, Fabricio Enembreck and Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{ADADRIFT}: An Adaptive Learning Technique for Long-History Stream-Based Recommender Systems  }</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ESWA</abbr></div>

        <!-- Entry bib key -->
        <div id="BARDDAL_LESSONS_LEARNED:2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Lessons learned from data stream classification applied to credit scoring</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Lucas Loezer, Fabrício Enembreck, and Riccardo Lanzuolo</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Expert Systems with Applications</em> --><div class="periodical">
            <em>Expert Systems with Applications</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/lessons_credit_scoring.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The financial credibility of a person is a factor used to determine whether a loan should be approved or not, and this is quantified by a ‘credit score,’ which is calculated using a variety of factors, including past performance on debt obligations, profiling, amongst others. Machine learning has been widely applied to automate the development of effective credit scoring models over the years. Yet, studies show that the development of robust credit scoring models may take longer than a year, and thus, if the behavior of customers changes over time, the model will be outdated even before its deployment. In this paper, we made 3 anonymized real-world credit scoring datasets available alongside the results obtained. In each of these datasets, we verify whether the credit scoring task should be thought as an ephemeral scenario since many of the variables may drift over time, and thus, data stream mining techniques should be used since they were tailored for incremental learning and to detect and adapt to changes in the data distribution. Therefore, we compare both traditional batch machine learning algorithms with data stream algorithms in different validation schemes using both Kolmogorov–Smirnov and Population Stability Index metrics. Furthermore, we also provide insights on the importance of features according to their Information Value, Mean Decrease Impurity, and Mean Positional Gain metrics, such that the last depicts changes in the importance of features over time. For 2 of the 3 tested datasets, the results obtained by data stream learners are comparable to predictive models currently in use, thus showing the efficiency of data stream classification for the credit scoring task.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">BARDDAL_LESSONS_LEARNED:2020</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Lessons learned from data stream classification applied to credit scoring}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Expert Systems with Applications}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{113899}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0957-4174}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.eswa.2020.113899}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.sciencedirect.com/science/article/pii/S0957417420306928}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Loezer, Lucas and Enembreck, Fabrício and Lanzuolo, Riccardo}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Credit scoring, Machine learning datasets, Data stream classification}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ANN. TELECOM.</abbr></div>

        <!-- Entry bib key -->
        <div id="Barddal_Enembreck:2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Regularized and incremental decision trees for data streams</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, and Fabricio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Annals of Telecommunications</em> --><div class="periodical">
            <em>Annals of Telecommunications</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/regularized_ht.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Decision trees are a widely used family of methods for learning predictive models from both batch and streaming data. Despite depicting positive results in a multitude of applications, incremental decision trees continuously grow in terms of nodes as new data becomes available, i.e., they eventually split on all features available, and also multiple times using the same feature; thus leading to unnecessary complexity and overfitting. With this behavior, incremental trees lose the ability to generalize well, be human-understandable and computationally efficient. To tackle these issues, we proposed in a previous study a regularization scheme for Hoeffding decision trees that: (i) uses a penalty factor to control the gain obtained by creating a new split node using a feature that has not been used thus far; and (ii) uses information from previous splits in the current branch to determine whether the gain observed indeed justifies a new split. In this paper, we extend this analysis and apply the proposed regularization scheme to other types of incremental decision trees and report the results in both synthetic and real-world scenarios. The main interest is to verify whether and how the proposed regularization scheme affects the different types of incremental trees. Results show that in addition to the original Hoeffding Tree, the Adaptive Random Forest also benefits from regularization, yet, McDiarmid Trees and Extremely Fast Decision trees observe declines in accuracy.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Barddal_Enembreck:2020</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Enembreck, Fabricio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Regularized and incremental decision trees for data streams}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Annals of Telecommunications}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCNN</abbr></div>

        <!-- Entry bib key -->
        <div id="Hochuli2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">An End-to-End Approach for Recognition of Modern and Historical Handwritten Numeral Strings</div>
          <!-- Author -->
          <div class="author">
          

          André Gustavo Hochuli, Alceu Souza Britto Jr., <em>Jean Paul Barddal</em>, Luiz Eduardo Soares Oliveira, and Robert Sabourin</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the 2020 International Joint Conference on Neural Networks (IJCNN)
               Glasgow, Scotland</em> --><div class="periodical">
            <em>In Proceedings of the 2020 International Joint Conference on Neural Networks (IJCNN)
               Glasgow, Scotland</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/end2end_hochuli.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>An end-to-end solution for handwritten numeral string recognition is proposed, in which the numeral string is considered as composed of objects automatically detected and recognized by a YoLo-based model. The main contribution of this paper is to avoid heuristic-based methods for string preprocessing and segmentation, the need for task-oriented classifiers, and also the use of specific constraints related to the string length. A robust experimental protocol based on several numeral string datasets, including one composed of historical documents, has shown that the proposed method is a feasible end-to-end solution for numeral string recognition. Besides, it reduces the complexity of the string recognition task considerably since it drops out classical steps, in special preprocessing, segmentation, and a set of classifiers devoted to strings with a specific length.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Hochuli2020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hochuli, Andr\'{e} Gustavo and de Souza Britto Jr., Alceu and Barddal, Jean Paul and Oliveira, Luiz Eduardo Soares and Sabourin, Robert}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An End-to-End Approach for Recognition of Modern and Historical Handwritten Numeral Strings}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2020 International Joint Conference on Neural Networks (IJCNN)
                 Glasgow, Scotland}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SAC</abbr></div>

        <!-- Entry bib key -->
        <div id="Loezer2020" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Cost-sensitive learning for imbalanced data streams</div>
          <!-- Author -->
          <div class="author">
          

          Lucas Loezer, Fabricio Enembreck, <em>Jean Paul Barddal</em>, and Alceu Souza Britto Jr.</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the 34rd Annual ACM Symposium on Applied Computing,
               SAC 2020, Brno, Czech Republic, March 30 - April 3, 2020</em> --><div class="periodical">
            <em>In Proceedings of the 34rd Annual ACM Symposium on Applied Computing,
               SAC 2020, Brno, Czech Republic, March 30 - April 3, 2020</em> 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/loezer2020.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The data imbalance problem hampers the classification task. In streaming environments, this becomes even more cumbersome as the proportion of classes can vary over time. Approaches based on misclassification costs can be used to mitigate this problem. In this paper, we present the Cost-sensitive Adaptive Random Forest (CSARF) and compare it to the Adaptive Random Forest (ARF) and ARF with Resampling (ARF_RE) in six real-world and six synthetic data sets with different class ratios. The empirical study analyzes two misclassification costs strategies of the CSARF and shows that the CSARF obtained statistically superior w.r.t. the average recall and average F1 when compared to ARF.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Loezer2020</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Loezer, Lucas and Enembreck, Fabricio and Barddal, Jean Paul and de Souza Britto Jr., Alceu}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Cost-sensitive learning for imbalanced data streams}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 34rd Annual {ACM} Symposium on Applied Computing,
                 {SAC} 2020, Brno, Czech Republic, March 30 - April 3, 2020}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"></div>

        <!-- Entry bib key -->
        <div id="Obladen2019" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">ANÁLISE PREDITIVA E DECISÕES JUDICIAIS: controvérsia ou realidade?</div>
          <!-- Author -->
          <div class="author">
          

          Cinthia Obladen Almendra Freitas, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Revista Democracia Digital e Governo Eletrônico</em> --><div class="periodical">
            <em>Revista Democracia Digital e Governo Eletrônico</em> Jan 2020
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/obladen_2020.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>In this paper, we provide an overview of how Data Analytics, Big Data, and Machine Learning may assist the judicial system by providing insightful information to citizens, police, lawyers, and judges, in a fast and accurate way. We conduct a bidirectional analysis between Law and Predictive Analytics applying the deductive method and bibliographic technique. We report concerns that Law should have with the application of computational techniques in different scenarios, mainly in the judicial system. Finally, we bring forward controversies between these areas, such as the new companies that target the use of personal and sensitive data in Law applications, and how these are potentially hurting fundamental rights and leading to biases in critical systems, wuch as predictive systems for crime recidivism.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Obladen2019</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://buscalegis.ufsc.br/revistas/index.php/observatoriodoegov/article/view/314}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{107--126}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{de Almendra Freitas, Cinthia Obladen and Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{AN\'{A}LISE PREDITIVA E DECIS\~{O}ES JUDICIAIS: controvérsia ou realidade?}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Revista Democracia Digital e Governo Eletrônico}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2019</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACM SIGKDD</abbr></div>

        <!-- Entry bib key -->
        <div id="Gomes2019" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Machine learning for streaming data</div>
          <!-- Author -->
          <div class="author">
          

          Heitor Murilo Gomes, Jesse Read, Albert Bifet, <em>Jean Paul Barddal</em>, and João Gama</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>ACM SIGKDD Explorations Newsletter</em> --><div class="periodical">
            <em>ACM SIGKDD Explorations Newsletter</em> Nov 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/sigkdd.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Incremental learning, online learning, and data stream learning are terms commonly associated with learning algorithms that update their models given a continuous influx of data without performing multiple passes over data. Several works have been devoted to this area, either directly or indirectly as characteristics of big data processing, i.e., Velocity and Volume. Given the current industry needs, there are many challenges to be addressed before existing methods can be efficiently applied to real-world problems. In this work, we focus on elucidating the connections among the current state-of-the-art on related fields; and clarifying open challenges in both academia and industry. We treat with special care topics that were not thoroughly investigated in past position and survey papers. This work aims to evoke discussion and elucidate the current research opportunities, highlighting the relationship of different subareas and suggesting courses of action when possible.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Gomes2019</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3373464.3373470}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3373464.3373470}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">nov</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery ({ACM})}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{21}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{6--22}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gomes, Heitor Murilo and Read, Jesse and Bifet, Albert and Barddal, Jean Paul and Gama, Jo{\~{a}}o}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Machine learning for streaming data}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{ACM} {SIGKDD} Explorations Newsletter}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SIGAPP ACR</abbr></div>

        <!-- Entry bib key -->
        <div id="JOURNAL_FRANKIE" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Addressing Feature Drift in Data Streams Using Iterative Subset Selection</div>
          <!-- Author -->
          <div class="author">
          

          Lanqin Yuan, Bernhard Pfahringer, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>SIGAPP Appl. Comput. Rev.</em> --><div class="periodical">
            <em>SIGAPP Appl. Comput. Rev.</em> Apr 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/lanqin_journal.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data streams are prone to various forms of concept drift over time including, for instance, changes to the relevance of features. This specific kind of drift is known as feature drift and requires techniques tailored not only to determine which features are the most important but also to take advantage of them. Feature selection has been studied and shown to improve classifier performance in standard batch data mining, yet it is mostly unexplored in data stream mining. This paper presents a novel method of feature subset selection specialized for dealing with the occurrence of feature drifts called Iterative Subset Selection (ISS), which splits the feature selection process into two stages by first ranking the features using some scoring function, and then iteratively selecting feature subsets using this ranking. This work further extends upon our prior work by exploring feeding information from the subset selection stage back into the ranking process. Applying our method to the Naïve Bayes and k-Nearest Neighbour classifier, we obtain compelling accuracy improvements when compared to existing works.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">JOURNAL_FRANKIE</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yuan, Lanqin and Pfahringer, Bernhard and Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Addressing Feature Drift in Data Streams Using Iterative Subset Selection}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{SIGAPP Appl. Comput. Rev.}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{March 2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{19}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1559-6915}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{20--33}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{14}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://doi.acm.org/10.1145/3325061.3325063}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3325061.3325063}</span><span class="p">,</span>
  <span class="na">acmid</span> <span class="p">=</span> <span class="s">{3325063}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{ACM}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{backward feature elimination, concept drift, data stream mining, embedded feature selection, feature selection, iterative subset selection}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCNN</abbr></div>

        <!-- Entry bib key -->
        <div id="VHPRE" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Vertical and Horizontal Partitioning in Data Stream Regression Ensembles</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 2019 International Joint Conference on Neural Networks, IJCNN 2019,
               Budapest, Hungary, July 14-19, 2019</em> --><div class="periodical">
            <em>In 2019 International Joint Conference on Neural Networks, IJCNN 2019,
               Budapest, Hungary, July 14-19, 2019</em> Apr 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/vertical_horizontal_regression.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data stream mining is an emerging topic in machine learning that targets the creation and update of predictive models over time as new data becomes available. Regarding existing works, classification is the most widely tackled task, which leaves regression nearly untouched. In this paper, the focus relies on ensemble learning for data stream regression, more specifically on vertical and horizontal data partitioning techniques. The goal is to determine whether and under which conditions partitioning can lessen the error rates of different types of learners in the data stream regression task. The proposed method combines vertical and horizontal partitioning, and it is compared with and against different types of learners and existing ensembles.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">VHPRE</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Vertical and Horizontal Partitioning in Data Stream Regression Ensembles}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 International Joint Conference on Neural Networks, {IJCNN} 2019,
                 Budapest, Hungary, July 14-19, 2019}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SAC</abbr></div>

        <!-- Entry bib key -->
        <div id="REGULARIZED_HTS" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Learning Regularized Hoeffding Trees from Data Streams</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, and Fabricio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the 34rd Annual ACM Symposium on Applied Computing,
               SAC 2019, Limassol, Cyprus, April 08-12, 2019</em> --><div class="periodical">
            <em>In Proceedings of the 34rd Annual ACM Symposium on Applied Computing,
               SAC 2019, Limassol, Cyprus, April 08-12, 2019</em> Apr 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/regularized_ht_sac.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Learning from data streams is a hot topic in machine learning that targets the learning and update of predictive models as data becomes available for both training and query. Due to their simplicity and convincing results in a multitude of applications, Hoeffding Trees are, by far, the most widely used family of methods for learning decision trees from streaming data. Despite the aforementioned positive characteristics, Hoeffding Trees tend to continuously grow in terms of nodes as new data becomes available, i.e., they eventually split on all features available, and multiple times on the same feature; thus leading to unnecessary complexity. With this behavior, Hoeffding Trees lose the ability to be human-understandable and computationally efficient. To tackle these issues, we propose a regularization scheme for Hoeffding Trees that (i) uses a penalty factor to control the gain obtained by creating a new split node using a feature that has not been used thus far; and (ii) uses information from previous splits in the current branch to determine whether the gain observed indeed justifies a new split. The proposed scheme is combined with both standard and adaptive variants of Hoeffding Trees. Experiments using real-world, stationary and drifting synthetic data show that the proposed method prevents both original and adaptive Hoeffding Trees from unnecessarily growing while maintaining impressive accuracy rates. As a byproduct of the regularization process, significant improvements in processing time, model complexity, and memory consumption have also been observed, thus showing the effectiveness of the proposed regularization scheme.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">REGULARIZED_HTS</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Enembreck, Fabricio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning Regularized Hoeffding Trees from Data Streams}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 34rd Annual {ACM} Symposium on Applied Computing,
                 {SAC} 2019, Limassol, Cyprus, April 08-12, 2019}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SAC</abbr></div>

        <!-- Entry bib key -->
        <div id="KARAX_TREE_FEATURE_IMPORTANCE" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Decision tree-based Feature Ranking in Concept Drifting Data Streams</div>
          <!-- Author -->
          <div class="author">
          

          Andreia Malucelli Jean Antonio Karax, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the 34rd Annual ACM Symposium on Applied Computing,
               SAC 2019, Limassol, Cyprus, April 08-12, 2019</em> --><div class="periodical">
            <em>In Proceedings of the 34rd Annual ACM Symposium on Applied Computing,
               SAC 2019, Limassol, Cyprus, April 08-12, 2019</em> Apr 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/karax2019.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data stream mining targets the learning of predictive models that evolve over time according to changes in arriving data. Throughout the years, several approaches have been tailored to create and continuously update predictive models from these streams, and from these, Hoeffding Trees became a popular choice for learning decision trees from data streams. In this paper, we aim at quantifying and expressing the importance of features in dynamic scenarios is of the utmost importance as they allow domain experts to back up, or invalidate, a predictive model. Therefore, we propose and assess a positional gain method tailored for for both individual and ensembles of Hoeffding Trees and how these behave in both synthetic and real-world scenarios.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">KARAX_TREE_FEATURE_IMPORTANCE</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jean Antonio Karax, Andreia Malucelli and Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Decision tree-based Feature Ranking in Concept Drifting Data Streams}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 34rd Annual {ACM} Symposium on Applied Computing,
                 {SAC} 2019, Limassol, Cyprus, April 08-12, 2019}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">INFSYS</abbr></div>

        <!-- Entry bib key -->
        <div id="BARDDAL201913" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Boosting decision stumps for dynamic feature selection on data streams</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Fabrício Enembreck, Heitor Murilo Gomes, Albert Bifet, and Bernhard Pfahringer</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Information Systems</em> --><div class="periodical">
            <em>Information Systems</em> Apr 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/boostingdecisionstumps.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Feature selection targets the identification of which features of a dataset are relevant to the learning task. It is also widely known and used to improve computation times, reduce computation requirements, and to decrease the impact of the curse of dimensionality and enhancing the generalization rates of classifiers. In data streams, classifiers shall benefit from all the items above, but more importantly, from the fact that the relevant subset of features may drift over time. In this paper, we propose a novel dynamic feature selection method for data streams called Adaptive Boosting for Feature Selection (ABFS). ABFS chains decision stumps and drift detectors, and as a result, identifies which features are relevant to the learning task as the stream progresses with reasonable success. In addition to our proposed algorithm, we bring feature selection-specific metrics from batch learning to streaming scenarios. Next, we evaluate ABFS according to these metrics in both synthetic and real-world scenarios. As a result, ABFS improves the classification rates of different types of learners and eventually enhances computational resources usage.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">BARDDAL201913</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Boosting decision stumps for dynamic feature selection on data streams}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Information Systems}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{83}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{13 - 29}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0306-4379}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.is.2019.02.003}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.sciencedirect.com/science/article/pii/S0306437918303399}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Enembreck, Fabrício and Gomes, Heitor Murilo and Bifet, Albert and Pfahringer, Bernhard}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Data stream mining, Feature selection, Concept drift, Feature drift}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ESWA</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:journals/eswa/BarddalEGBP19" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Merit-guided dynamic feature selection filter for data streams</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Fabrı́cio Enembreck, Heitor Murilo Gomes, Albert Bifet, and Bernhard Pfahringer</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Expert Syst. Appl.</em> --><div class="periodical">
            <em>Expert Syst. Appl.</em> Apr 2019
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/merit.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Learning from ephemeral data streams has garnered the interest of both researchers and practitioners towards adaptive learning techniques. Despite the convincing results obtained thus far, most of the current research still overlooks that the relevance of features may change throughout the learning process. Scenarios where features become - or cease to be - relevant to the learning task are called feature drifting data streams, and the identification of which features are relevant becomes even more challenging when the feature space is high-dimensional. To select relevant features during the progress of data streams, we propose a merit-guided and classifier-independent dynamic feature selection algorithm named DynamIc SymmetriCal Uncertainty Selection for Streams (DISCUSS). We evaluate our proposal on both synthetic and real-world datasets and show that DISCUSS can boost kNN and Naive Bayes classifiers’ accuracy rates on high-dimensional data streams, while at the expense of limited processing time and memory space. Finally, the drawbacks of the proposed method are assessed, and possible future works on the topic are also discussed.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/eswa/BarddalEGBP19</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Enembreck, Fabr{\'{\i}}cio and Gomes, Heitor Murilo and Bifet, Albert and Pfahringer, Bernhard}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Merit-guided dynamic feature selection filter for data streams}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Expert Syst. Appl.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{116}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{227--242}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.eswa.2018.09.031}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.eswa.2018.09.031}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Fri, 02 Nov 2018 15:38:38 +0100}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/journals/eswa/BarddalEGBP19}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2018</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ESANN</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/esann/GomesBFB18" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Adaptive random forests for data stream regression</div>
          <!-- Author -->
          <div class="author">
          

          Heitor Murilo Gomes, <em>Jean Paul Barddal</em>, Luis Eduardo Boiko Ferreira, and Albert Bifet</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 26th European Symposium on Artificial Neural Networks, ESANN 2018,
               Bruges, Belgium, April 25-27, 2018</em> --><div class="periodical">
            <em>In 26th European Symposium on Artificial Neural Networks, ESANN 2018,
               Bruges, Belgium, April 25-27, 2018</em> Apr 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/arf_regression.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data stream mining is a hot topic in the machine learning community that tackles the problem of learning and updating predictive models as new data becomes available over time. Even though several new methods are proposed every year, most focus on the classification task and overlook the regression task. In this paper, we propose an adaptation to the Adaptive Random Forest so that it can handle regression tasks, namely ARF-Reg. ARF-Reg is empirically evaluated and compared to the state-of-the-art data stream regression algorithms, thus highlighting its applicability in different data stream scenarios.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/esann/GomesBFB18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gomes, Heitor Murilo and Barddal, Jean Paul and Ferreira, Luis Eduardo Boiko and Bifet, Albert}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adaptive random forests for data stream regression}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{26th European Symposium on Artificial Neural Networks, {ESANN} 2018,
                 Bruges, Belgium, April 25-27, 2018}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/esann/2018}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Fri, 09 Nov 2018 12:29:56 +0100}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/esann/GomesBFB18}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCNN</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/ijcnn/FerreiraBEG18" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">An Experimental Perspective on Sampling Methods for Imbalanced Learning
               From Financial Databases</div>
          <!-- Author -->
          <div class="author">
          

          Luis Eduardo Boiko Ferreira, <em>Jean Paul Barddal</em>, Fabrı́cio Enembreck, and Heitor Murilo Gomes</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 2018 International Joint Conference on Neural Networks, IJCNN 2018,
               Rio de Janeiro, Brazil, July 8-13, 2018</em> --><div class="periodical">
            <em>In 2018 International Joint Conference on Neural Networks, IJCNN 2018,
               Rio de Janeiro, Brazil, July 8-13, 2018</em> Apr 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/experimental.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The financial market is one of the major consumers of data mining techniques, and the main reason is their efficiency to analyze complex data. One important trait shared between most financial applications is class imbalance. Since traditional classification methods assume nearly balanced classes and equal misclassification costs, they usually fail to deal with imbalanced data. However, in financial contexts, problems are usually imbalanced, and instances from the minority class are known for deficits of millions of dollars every year, e.g., credit card frauds, money laundering transactions and so forth. Over the years, several techniques for dealing with class imbalance have been developed, such as sampling techniques and algorithm adaptations. In this study, we analyze how different sampling techniques impact the performance of different classification systems on financial applications. Results show that, for the given datasets, sampling techniques allow the improvement of prediction performance of the minority class while also improving overall classification rates. Nevertheless, their use often deteriorates the performance in predicting the majority class.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/ijcnn/FerreiraBEG18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ferreira, Luis Eduardo Boiko and Barddal, Jean Paul and Enembreck, Fabr{\'{\i}}cio and Gomes, Heitor Murilo}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An Experimental Perspective on Sampling Methods for Imbalanced Learning
                 From Financial Databases}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2018 International Joint Conference on Neural Networks, {IJCNN} 2018,
                 Rio de Janeiro, Brazil, July 8-13, 2018}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--6}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/ijcnn/2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/IJCNN.2018.8489290}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IJCNN.2018.8489290}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Mon, 22 Oct 2018 13:07:32 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/ijcnn/FerreiraBEG18}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">INDIN</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/indin/SearaMSB18" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Are fintechs really a hype? A machine learning-based polarity analysis
               of Brazilian posts on social media</div>
          <!-- Author -->
          <div class="author">
          

          Marina Ponestke Seara, Andreia Malucelli, Altair Olivo Santin, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 16th IEEE International Conference on Industrial Informatics, INDIN
               2018, Porto, Portugal, July 18-20, 2018</em> --><div class="periodical">
            <em>In 16th IEEE International Conference on Industrial Informatics, INDIN
               2018, Porto, Portugal, July 18-20, 2018</em> Apr 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/fintechs.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Fintechs are technology companies that, in contrast to traditional banks, are engaged in digital solutions for payment, money transfers, and real-time notifications. Taking advantage of digital means of communication, most of the service interactions between fintechs and customers occurs via chats or posts in social media. In this work, our goal is to use machine learning to analyze these posts and identify what are the terms used by customers to express positive, neutral and negative customer experiences. During this analysis, we assess the following questions using data from the 3 biggest fintechs in Brazil: (i) what are the most commented topics on social media regarding fintechs, (ii) what are the words more often used by customers to express positive, negative and neutral reactions to the customer service obtained; and (iii) what kind of machine learning model should a fintech use to automatically identify whether a post is positive, negative or neutral.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/indin/SearaMSB18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Seara, Marina Ponestke and Malucelli, Andreia and Santin, Altair Olivo and Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Are fintechs really a hype? {A} machine learning-based polarity analysis
                 of Brazilian posts on social media}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{16th {IEEE} International Conference on Industrial Informatics, {INDIN}
                 2018, Porto, Portugal, July 18-20, 2018}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{233--238}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/indin/2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/INDIN.2018.8471986}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/INDIN.2018.8471986}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Fri, 12 Oct 2018 10:26:41 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/indin/SearaMSB18}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SAC</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/sac/YuanPB18" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Iterative subset selection for feature drifting data streams</div>
          <!-- Author -->
          <div class="author">
          

          Lanqin Yuan, Bernhard Pfahringer, and <em>Jean Paul Barddal</em>
</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the 33rd Annual ACM Symposium on Applied Computing,
               SAC 2018, Pau, France, April 09-13, 2018</em> --><div class="periodical">
            <em>In Proceedings of the 33rd Annual ACM Symposium on Applied Computing,
               SAC 2018, Pau, France, April 09-13, 2018</em> Apr 2018
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/lanqin_sac.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Feature selection has been studied and shown to improve classifier performance in standard batch data mining but is mostly unexplored in data stream mining. Feature selection becomes even more important when the relevant subset of features changes over time, as the underlying concept of a data stream drifts. This specific kind of drift is known as feature drift and requires specific techniques not only to determine which features are the most important but also to take advantage of them. This paper presents a novel method of feature subset selection specialized for dealing with the occurrence of feature drifts called Iterative Subset Selection (ISS), which splits the feature selection process into two stages by first ranking the features, and then iteratively selecting features from the ranking. Applying our feature selection method together with Naive Bayes or k-Nearest Neighbour as a classifier, results in compelling accuracy improvements, compared to prior work.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/sac/YuanPB18</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yuan, Lanqin and Pfahringer, Bernhard and Barddal, Jean Paul}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Iterative subset selection for feature drifting data streams}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 33rd Annual {ACM} Symposium on Applied Computing,
                 {SAC} 2018, Pau, France, April 09-13, 2018}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{510--517}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/sac/2018}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3167132.3167188}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3167132.3167188}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Wed, 21 Nov 2018 12:43:56 +0100}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/sac/YuanPB18}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2017</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ACM CSUR</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:journals/csur/GomesBEB17" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Survey on Ensemble Learning for Data Stream Classification</div>
          <!-- Author -->
          <div class="author">
          

          Heitor Murilo Gomes, <em>Jean Paul Barddal</em>, Fabrı́cio Enembreck, and Albert Bifet</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>ACM Comput. Surv.</em> --><div class="periodical">
            <em>ACM Comput. Surv.</em> Apr 2017
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/survey_ensemble_learning.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Ensemble-based methods are among the most widely used techniques for data stream classification. Their popularity is attributable to their good performance in comparison to strong single learners while being relatively easy to deploy in real-world applications. Ensemble algorithms are especially useful for data stream learning as they can be integrated with drift detection algorithms and incorporate dynamic updates, such as selective removal or addition of classifiers. This work proposes a taxonomy for data stream ensemble learning as derived from reviewing over 60 algorithms. Important aspects such as combination, diversity, and dynamic updates, are thoroughly discussed. Additional contributions include a listing of popular open-source tools and a discussion about current data stream research challenges and how they relate to ensemble learning (big data streams, concept evolution, feature drifts, temporal dependencies, and others).</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/csur/GomesBEB17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gomes, Heitor Murilo and Barddal, Jean Paul and Enembreck, Fabr{\'{\i}}cio and Bifet, Albert}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Survey on Ensemble Learning for Data Stream Classification}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{ACM} Comput. Surv.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{50}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{23:1--23:36}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3054925}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3054925}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Fri, 30 Nov 2018 12:48:46 +0100}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/journals/csur/GomesBEB17}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">JSS</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:journals/jss/BarddalGEP17" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A survey on feature drift adaptation: Definition, benchmark, challenges
               and future directions</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, Fabrı́cio Enembreck, and Bernhard Pfahringer</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Journal of Systems and Software</em> --><div class="periodical">
            <em>Journal of Systems and Software</em> Apr 2017
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/survey_feature_drift.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data stream mining is a fast growing research topic due to the ubiquity of data in several real-world problems. Given their ephemeral nature, data stream sources are expected to undergo changes in data distribution, a phenomenon called concept drift. This paper focuses on one specific type of drift that has not yet been thoroughly studied, namely feature drift. Feature drift occurs whenever a subset of features becomes, or ceases to be, relevant to the learning task; thus, learners must detect and adapt to these changes accordingly. We survey existing work on feature drift adaptation with both explicit and implicit approaches. Additionally, we benchmark several algorithms and a naive feature drift detection approach using synthetic and real-world datasets. The results from our experiments indicate the need for future research in this area as even naive approaches produced gains in accuracy while reducing resources usage. Finally, we state current research topics, challenges and future directions for feature drift adaptation.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/jss/BarddalGEP17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{\i}}cio and Pfahringer, Bernhard}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A survey on feature drift adaptation: Definition, benchmark, challenges
                 and future directions}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Journal of Systems and Software}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{127}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{278--294}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.jss.2016.07.005}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.jss.2016.07.005}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Tue, 06 Jun 2017 22:24:00 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/journals/jss/BarddalGEP17}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ML</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:journals/ml/GomesBRBEPHA17" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Adaptive random forests for evolving data stream classification</div>
          <!-- Author -->
          <div class="author">
          

          Heitor Murilo Gomes, Albert Bifet, Jesse Read, <em>Jean Paul Barddal</em>, Fabrı́cio Enembreck, Bernhard Pfharinger, Geoff Holmes, and Talel Abdessalem</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Machine Learning</em> --><div class="periodical">
            <em>Machine Learning</em> Apr 2017
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/arf.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Random forests is currently one of the most used machine learning algorithms in the non-streaming (batch) setting. This preference is attributable to its high learning performance and low demands with respect to input preparation and hyper-parameter tuning. However, in the challenging context of evolving data streams, there is no random forests algorithm that can be considered state-of-the-art in comparison to bagging and boosting based algorithms. In this work, we present the adaptive random forest (ARF) algorithm for classification of evolving data streams. In contrast to previous attempts of replicating random forests for data stream learning, ARF includes an effective resampling method and adaptive operators that can cope with different types of concept drifts without complex optimizations for different data sets. We present experiments with a parallel implementation of ARF which has no degradation in terms of classification performance in comparison to a serial implementation, since trees and adaptive operators are independent from one another. Finally, we compare ARF with state-of-the-art algorithms in a traditional test-then-train evaluation and a novel delayed labelling evaluation, and show that ARF is accurate and uses a feasible amount of resources.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/ml/GomesBRBEPHA17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gomes, Heitor Murilo and Bifet, Albert and Read, Jesse and Barddal, Jean Paul and Enembreck, Fabr{\'{\i}}cio and Pfharinger, Bernhard and Holmes, Geoff and Abdessalem, Talel}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Adaptive random forests for evolving data stream classification}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Machine Learning}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{106}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{9-10}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1469--1495}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/s10994-017-5642-8}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10994-017-5642-8}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Tue, 26 Jun 2018 14:09:25 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/journals/ml/GomesBRBEPHA17}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICTAI</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/ictai/FerreiraBGE17" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Improving Credit Risk Prediction in Online Peer-to-Peer (P2P) Lending
               Using Imbalanced Learning Techniques</div>
          <!-- Author -->
          <div class="author">
          

          Luis Eduardo Boiko Ferreira, <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, and Fabrı́cio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 29th IEEE International Conference on Tools with Artificial Intelligence,
               ICTAI 2017, Boston, MA, USA, November 6-8, 2017</em> --><div class="periodical">
            <em>In 29th IEEE International Conference on Tools with Artificial Intelligence,
               ICTAI 2017, Boston, MA, USA, November 6-8, 2017</em> Apr 2017
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/p2p_resampling.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Peer-to-peer (P2P) lending is a global trend of financial markets that allow individuals to obtain and concede loans without having financial institutions as a strong proxy. As many real-world applications, P2P lending presents an imbalanced characteristic, where the number of creditworthy loan requests is much larger than the number of non-creditworthy ones. In this work, we wrangle a real-world P2P lending data set from Lending Club, containing a large amount of data gathered from 2007 up to 2016. We analyze how supervised classification models and techniques to handle class imbalance impact creditworthiness prediction rates. Ensembles, cost-sensitive and sampling methods are combined and evaluated along logistic regression, decision tree, and bayesian learning schemes. Results show that, in average, sampling techniques outperform ensembles and cost sensitive approaches.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/ictai/FerreiraBGE17</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ferreira, Luis Eduardo Boiko and Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{\i}}cio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Improving Credit Risk Prediction in Online Peer-to-Peer {(P2P)} Lending
                 Using Imbalanced Learning Techniques}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{29th {IEEE} International Conference on Tools with Artificial Intelligence,
                 {ICTAI} 2017, Boston, MA, USA, November 6-8, 2017}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{175--181}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/ictai/2017}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICTAI.2017.00037}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICTAI.2017.00037}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Tue, 31 Jul 2018 12:20:29 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/ictai/FerreiraBGE17}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2016</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">INFSYS</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:journals/is/BarddalGEB16" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">SNCStream+: Extending a high quality true anytime
               data stream clustering algorithm</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, Fabrı́cio Enembreck, and Jean-Paul A. Barthès</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>Inf. Syst.</em> --><div class="periodical">
            <em>Inf. Syst.</em> Apr 2016
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/sncstreamplus.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data Stream Clustering is an active area of research which requires efficient algorithms capable of finding and updating clusters incrementally as data arrives. On top of that, due to the inherent evolving nature of data streams, it is expected that algorithms undergo both concept drifts and evolutions, which must be taken into account by the clustering algorithm, allowing incremental clustering updates. In this paper we present the Social Network Clusterer Stream+ (SNCStream+). SNCStream+ tackles the data stream clustering problem as a network formation and evolution problem, where instances and micro-clusters form clusters based on homophily. Our proposal has its parameters analyzed and it is evaluated in a broad set of problems against literature baselines. Results show that SNCStream+ achieves superior clustering quality (CMM), and feasible processing time and memory space usage when compared to the original SNCStream and other proposals of the literature.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/is/BarddalGEB16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{\i}}cio and Barth{\`{e}}s, Jean{-}Paul A.}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SNCStream+: Extending a high quality true anytime
                 data stream clustering algorithm}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Inf. Syst.}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{62}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{60--73}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.is.2016.06.007}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.is.2016.06.007}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Tue, 06 Jun 2017 22:22:00 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/journals/is/BarddalGEB16}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICPR</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/icpr/BarddalGBE16" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A benchmark of classifiers on feature drifting data streams</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, Alceu Souza Britto Jr., and Fabrı́cio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 23rd International Conference on Pattern Recognition, ICPR 2016,
               Cancún, Mexico, December 4-8, 2016</em> --><div class="periodical">
            <em>In 23rd International Conference on Pattern Recognition, ICPR 2016,
               Cancún, Mexico, December 4-8, 2016</em> Apr 2016
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/benchmark_fd.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The ever increasing data generation confronts both practitioners and researchers on handling massive and sequentially generated amounts of information, the so-called data streams. In this context, a lot of effort has been put on the extraction of useful patterns from streaming scenarios. Learning from data streams embeds a variety of problems, and by far, the most challenging is concept drift, i.e. changes in data distribution. In this paper, we focus on a specific type of drift uncommonly assessed in the literature: feature drifts. Feature drifts occur whenever a subset of features becomes, or ceases to be, relevant to the concept to be learned. We propose and review several feature drifting data stream generators and use them to benchmark state-of-the-art data stream classification algorithms and their combination with drift detectors. Results show that, although drift detectors enable slight quicker recovery to feature drifts, best results are obtained by Hoeffding Adaptive Tree, the only learner that performs dynamic feature selection as streams progress.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/icpr/BarddalGBE16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Gomes, Heitor Murilo and de Souza Britto Jr., Alceu and Enembreck, Fabr{\'{\i}}cio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A benchmark of classifiers on feature drifting data streams}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{23rd International Conference on Pattern Recognition, {ICPR} 2016,
                 Canc{\'{u}}n, Mexico, December 4-8, 2016}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2180--2185}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/icpr/2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICPR.2016.7899959}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICPR.2016.7899959}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Wed, 24 May 2017 08:30:42 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/icpr/BarddalGBE16}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICPR</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/icpr/BarddalGGBE16" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Overcoming feature drifts via dynamic feature weighted k-nearest neighbor
               learning</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, Jones Granatyr, Alceu Souza Britto Jr., and Fabrı́cio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 23rd International Conference on Pattern Recognition, ICPR 2016,
               Cancún, Mexico, December 4-8, 2016</em> --><div class="periodical">
            <em>In 23rd International Conference on Pattern Recognition, ICPR 2016,
               Cancún, Mexico, December 4-8, 2016</em> Apr 2016
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/overcoming_fd_knn.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Extracting useful knowledge from data streams is problematic, mainly due to changes in their data distribution, a phenomenon named concept drift. Recently, studies have shown that most of existing algorithms for learning from data streams do not encompass techniques for a specific kind of drift: feature drifts. Feature drifts occur when features become, or cease to be, relevant to the learning task. In this paper, we propose an extension to the k-nearest neighbor classifier, so its distances’ computations are weighted according to their current discriminative power. On our proposal, the discriminative power of features is given by entropy, which is swiftly computed over a sliding window. Empirical evidence shows that our approach is able to overcome several existing algorithms in accuracy and feature drift adaptation, while at the expense of bounded processing time and memory space.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/icpr/BarddalGGBE16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Gomes, Heitor Murilo and Granatyr, Jones and de Souza Britto Jr., Alceu and Enembreck, Fabr{\'{\i}}cio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Overcoming feature drifts via dynamic feature weighted k-nearest neighbor
                 learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{23rd International Conference on Pattern Recognition, {ICPR} 2016,
                 Canc{\'{u}}n, Mexico, December 4-8, 2016}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2186--2191}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/icpr/2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICPR.2016.7899960}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICPR.2016.7899960}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Wed, 24 May 2017 08:30:48 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/icpr/BarddalGGBE16}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJCNN</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/ijcnn/GranatyrBAEG16" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Towards emotion-based reputation guessing learning agents</div>
          <!-- Author -->
          <div class="author">
          

          Jones Granatyr, <em>Jean Paul Barddal</em>, Adriano Weihmayer Almeida, Fabrı́cio Enembreck, and Adaiane Pereira Santos Granatyr</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 2016 International Joint Conference on Neural Networks, IJCNN 2016,
               Vancouver, BC, Canada, July 24-29, 2016</em> --><div class="periodical">
            <em>In 2016 International Joint Conference on Neural Networks, IJCNN 2016,
               Vancouver, BC, Canada, July 24-29, 2016</em> Apr 2016
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/emotion_guessing_agents.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Trust and reputation mechanisms are part of the logical protection of intelligent agents, preventing malicious agents from acting egotistically or with the intention to damage others. Several studies in Psychology, Neurology and Anthropology claim that emotions are part of human’s decision making process. However, there is a lack of understanding about how affective aspects, such as emotions, influence trust or reputation levels of intelligent agents when they are inserted into an information exchange environment, e.g. an evaluation system. In this paper we propose a reputation model that accounts for emotional bounds given by Ekman’s basic emotions and inductive machine learning. Our proposal is evaluated by extracting emotions from texts provided by two online human-fed evaluation systems. Empirical results show significant agent’s utility improvements with p &lt;; .05 when compared to non-emotion-wise proposals, thus, showing the need for future research in this area.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/ijcnn/GranatyrBAEG16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Granatyr, Jones and Barddal, Jean Paul and Almeida, Adriano Weihmayer and Enembreck, Fabr{\'{\i}}cio and dos Santos Granatyr, Adaiane Pereira}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards emotion-based reputation guessing learning agents}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2016 International Joint Conference on Neural Networks, {IJCNN} 2016,
                 Vancouver, BC, Canada, July 24-29, 2016}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{3801--3808}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/ijcnn/2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/IJCNN.2016.7727690}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IJCNN.2016.7727690}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Fri, 26 May 2017 00:50:11 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/ijcnn/GranatyrBAEG16}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ECML PKDD</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/pkdd/BarddalGEPB16" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">On Dynamic Feature Weighting for Feature Drifting Data Streams</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, Fabrı́cio Enembreck, Bernhard Pfahringer, and Albert Bifet</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Machine Learning and Knowledge Discovery in Databases - European Conference,
               ECML PKDD 2016, Riva del Garda, Italy, September 19-23, 2016,
               Proceedings, Part II</em> --><div class="periodical">
            <em>In Machine Learning and Knowledge Discovery in Databases - European Conference,
               ECML PKDD 2016, Riva del Garda, Italy, September 19-23, 2016,
               Proceedings, Part II</em> Apr 2016
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/dyn_feature_weighting.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The ubiquity of data streams has been encouraging the development of new incremental and adaptive learning algorithms. Data stream learners must be fast, memory-bounded, but mainly, tailored to adapt to possible changes in the data distribution, a phenomenon named concept drift. Recently, several works have shown the impact of a so far nearly neglected type of drifcccct: feature drifts. Feature drifts occur whenever a subset of features becomes, or ceases to be, relevant to the learning task. In this paper we (i) provide insights into how the relevance of features can be tracked as a stream progresses according to information theoretical Symmetrical Uncertainty; and (ii) how it can be used to boost two learning schemes: Naive Bayesian and k-Nearest Neighbor. Furthermore, we investigate the usage of these two new dynamically weighted learners as prediction models in the leaves of the Hoeffding Adaptive Tree classifier. Results show improvements in accuracy (an average of 10.69 % for k-Nearest Neighbor, 6.23 % for Naive Bayes and 4.42 % for Hoeffding Adaptive Trees) in both synthetic and real-world datasets at the expense of a bounded increase in both memory consumption and processing time.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/pkdd/BarddalGEPB16</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{\i}}cio and Pfahringer, Bernhard and Bifet, Albert}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On Dynamic Feature Weighting for Feature Drifting Data Streams}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Machine Learning and Knowledge Discovery in Databases - European Conference,
                 {ECML} {PKDD} 2016, Riva del Garda, Italy, September 19-23, 2016,
                 Proceedings, Part {II}}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{129--144}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/pkdd/2016-2}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-46227-1\_9}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-46227-1\_9}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Thu, 15 Jun 2017 21:40:02 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/pkdd/BarddalGEPB16}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>

  <h2 class="year">2015</h2>
  <ol class="bibliography">
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">IJNCR</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:journals/ijncr/BarddalGE15" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Advances on Concept Drift Detection in Regression Tasks Using Social
               Networks Theory</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, and Fabrı́cio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>IJNCR</em> --><div class="periodical">
            <em>IJNCR</em> Apr 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/ijncr.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Mining data streams is one of the main studies in machine learning area due to its application in many knowledge areas. One of the major challenges on mining data streams is concept drift, which requires the learner to discard the current concept and adapt to a new one. Ensemble-based drift detection algorithms have been used successfully to the classification task but usually maintain a fixed size ensemble of learners running the risk of needlessly spending processing time and memory. In this paper the authors present improvements to the Scale-free Network Regressor (SFNR), a dynamic ensemble-based method for regression that employs social networks theory. In order to detect concept drifts SFNR uses the Adaptive Window (ADWIN) algorithm. Results show improvements in accuracy, especially in concept drift situations and better performance compared to other state-of-the-art algorithms in both real and synthetic data.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">DBLP:journals/ijncr/BarddalGE15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{\i}}cio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Advances on Concept Drift Detection in Regression Tasks Using Social
                 Networks Theory}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{{IJNCR}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{26--41}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.4018/ijncr.2015010102}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.4018/ijncr.2015010102}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Sun, 28 May 2017 13:18:05 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/journals/ijncr/BarddalGE15}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICEIS</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/iceis/SouzaBGBE15" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Applying Ensemble-based Online Learning Techniques on Crime Forecasting</div>
          <!-- Author -->
          <div class="author">
          

          Anderson José Souza, André Pinz Borges, Heitor Murilo Gomes, <em>Jean Paul Barddal</em>, and Fabrı́cio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In ICEIS 2015 - Proceedings of the 17th International Conference on
               Enterprise Information Systems, Volume 1, Barcelona, Spain, 27-30
               April, 2015</em> --><div class="periodical">
            <em>In ICEIS 2015 - Proceedings of the 17th International Conference on
               Enterprise Information Systems, Volume 1, Barcelona, Spain, 27-30
               April, 2015</em> Apr 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/crime_forecasting.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Traditional prediction algorithms assume that the underlying concept is stationary, i.e., no changes are expected to happen during the deployment of an algorithm that would render it obsolete. Although, for many real world scenarios changes in the data distribution, namely concept drifts, are expected to occur due to variations in the hidden context, e.g., new government regulations, climatic changes, or adversary adaptation. In this paper, we analyze the problem of predicting the most susceptible types of victims of crimes occurred in a large city of Brazil. It is expected that criminals change their victims’ types to counter police methods and vice-versa. Therefore, the challenge is to obtain a model capable of adapting rapidly to the current preferred criminal victims, such that police resources can be allocated accordingly. In this type of problem the most appropriate learning models are provided by data stream mining, since the learning algorithms from this domain assume that concept drifts may occur over time, and are ready to adapt to them. In this paper we apply ensemble-based data stream methods, since they provide good accuracy and the ability to adapt to concept drifts. Results show that the application of these ensemble-based algorithms (Leveraging Bagging, SFNClassifier, ADWIN Bagging and Online Bagging) reach feasible accuracy for this task.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/iceis/SouzaBGBE15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{de Souza, Anderson Jos{\'{e}} and Borges, Andr{\'{e}} Pinz and Gomes, Heitor Murilo and Barddal, Jean Paul and Enembreck, Fabr{\'{\i}}cio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Applying Ensemble-based Online Learning Techniques on Crime Forecasting}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{ICEIS} 2015 - Proceedings of the 17th International Conference on
                 Enterprise Information Systems, Volume 1, Barcelona, Spain, 27-30
                 April, 2015}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{17--24}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/iceis/2015-1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.5220/0005335700170024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.5220/0005335700170024}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Wed, 17 May 2017 10:54:49 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/iceis/SouzaBGBE15}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICONIP</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/iconip/BarddalGE15" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Analyzing the Impact of Feature Drifts in Streaming Learning</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, and Fabrı́cio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Neural Information Processing - 22nd International Conference, ICONIP
               2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part I</em> --><div class="periodical">
            <em>In Neural Information Processing - 22nd International Conference, ICONIP
               2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part I</em> Apr 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/analyzing_feature_drifts.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Learning from data streams requires efficient algorithms capable of deriving a model accordingly to the arrival of new instances. Data streams are by definition unbounded sequences of data that are possibly non stationary, i.e. they may undergo changes in data distribution, phenomenon named concept drift. Concept drifts force streaming learning algorithms to detect and adapt to such changes in order to present feasible accuracy throughout time. Nonetheless, most of works presented in the literature do not account for a specific kind of drifts: feature drifts. Feature drifts occur whenever the relevance of an arbitrary attribute changes through time, also impacting the concept to be learned. In this paper we (i) verify the occurrence of feature drift in a publicly available dataset, (ii) present a synthetic data stream generator capable of performing feature drifts and (iii) analyze the impact of this type of drift in stream learning algorithms, enlightening that there is room and the need for dynamic feature selection strategies for data streams.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/iconip/BarddalGE15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{\i}}cio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Analyzing the Impact of Feature Drifts in Streaming Learning}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Neural Information Processing - 22nd International Conference, {ICONIP}
                 2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part {I}}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{21--28}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/iconip/2015-1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-26532-2\_3}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-26532-2\_3}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Sun, 08 Jul 2018 23:29:36 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/iconip/BarddalGE15}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICONIP</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/iconip/GomesCZBM15" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">On the Discovery of Time Distance Constrained Temporal Association
               Rules</div>
          <!-- Author -->
          <div class="author">
          

          Heitor Murilo Gomes, Deborah Ribeiro Carvalho, Lourdes Zubieta, <em>Jean Paul Barddal</em>, and Andreia Malucelli</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Neural Information Processing - 22nd International Conference, ICONIP
               2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part II</em> --><div class="periodical">
            <em>In Neural Information Processing - 22nd International Conference, ICONIP
               2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part II</em> Apr 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/temporalassociatedrules.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>The increased use of data mining algorithms reflects the need for automatic extraction of knowledge from large volumes of data. This work presents a temporal data mining algorithm that discovers frequent Association Rules from timestamped data. These rules are named Cause-Effect Rules, each represented by a multiset of unordered events (Cause) followed by a singleton event (Effect). Also, a Cause-Effect Rule is valid within an specific constraint that defines the minimum and maximum time distance between its Cause and Effect. Our algorithm was tested on a data set from two hospital emergency departments in Sherbrooke, QC, Canada.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/iconip/GomesCZBM15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gomes, Heitor Murilo and de Carvalho, Deborah Ribeiro and Zubieta, Lourdes and Barddal, Jean Paul and Malucelli, Andreia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{On the Discovery of Time Distance Constrained Temporal Association
                 Rules}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Neural Information Processing - 22nd International Conference, {ICONIP}
                 2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part {II}}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{510--519}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/iconip/2015-2}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-26535-3\_58}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-26535-3\_58}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Sun, 08 Jul 2018 23:29:36 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/iconip/GomesCZBM15}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICONIP</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/iconip/BarddalGE15a" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Complex Network-Based Anytime Data Stream Clustering Algorithm</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, and Fabrı́cio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Neural Information Processing - 22nd International Conference, ICONIP
               2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part I</em> --><div class="periodical">
            <em>In Neural Information Processing - 22nd International Conference, ICONIP
               2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part I</em> Apr 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/cndenstream.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data stream mining is an active area of research that poses challenging research problems. In the latter years, a variety of data stream clustering algorithms have been proposed to perform unsupervised learning using a two-step framework. Additionally, dealing with non-stationary, unbounded data streams requires the development of algorithms capable of performing fast and incremental clustering addressing time and memory limitations without jeopardizing clustering quality. In this paper we present CNDenStream, a one-step data stream clustering algorithm capable of finding non-hyper-spherical clusters which, in opposition to other data stream clustering algorithms, is able to maintain updated clusters after the arrival of each instance by using a complex network construction and evolution model based on homophily. Empirical studies show that CNDenStream is able to surpass other algorithms in clustering quality and requires a feasible amount of resources when compared to other algorithms presented in the literature.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/iconip/BarddalGE15a</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{\i}}cio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Complex Network-Based Anytime Data Stream Clustering Algorithm}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Neural Information Processing - 22nd International Conference, {ICONIP}
                 2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part {I}}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{615--622}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/iconip/2015-1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1007/978-3-319-26532-2\_68}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-26532-2\_68}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Sun, 08 Jul 2018 23:29:36 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/iconip/BarddalGE15a}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">ICTAI</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/ictai/BarddalGE15" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">A Survey on Feature Drift Adaptation</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, and Fabrı́cio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In 27th IEEE International Conference on Tools with Artificial Intelligence,
               ICTAI 2015, Vietri sul Mare, Italy, November 9-11, 2015</em> --><div class="periodical">
            <em>In 27th IEEE International Conference on Tools with Artificial Intelligence,
               ICTAI 2015, Vietri sul Mare, Italy, November 9-11, 2015</em> Apr 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/survey_fd.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data stream mining is a fast growing research topic due to the ubiquity of data in several real-world problems. Given their ephemeral nature, data stream sources are expected to undergo changes in data distribution, a phenomenon called concept drift. This paper focuses on one specific type of drift that has not yet been thoroughly studied, namely feature drift. Feature drift occurs whenever a subset of features becomes, or ceases to be, relevant to the learning task; thus, learners must detect and adapt to these changes accordingly. We survey existing work on feature drift adaptation with both explicit and implicit approaches. Additionally, we benchmark several algorithms and a naive feature drift detection approach using synthetic and real-world datasets. The results from our experiments indicate the need for future research in this area as even naive approaches produced gains in accuracy while reducing resources usage. Finally, we state current research topics, challenges and future directions for feature drift adaptation.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/ictai/BarddalGE15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{\i}}cio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Survey on Feature Drift Adaptation}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{27th {IEEE} International Conference on Tools with Artificial Intelligence,
                 {ICTAI} 2015, Vietri sul Mare, Italy, November 9-11, 2015}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1053--1060}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/ictai/2015}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1109/ICTAI.2015.150}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICTAI.2015.150}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Fri, 26 May 2017 00:51:05 +0200}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/ictai/BarddalGE15}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SAC</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/sac/BarddalGE15" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">SNCStream: a social network-based data stream clustering algorithm</div>
          <!-- Author -->
          <div class="author">
          

          <em>Jean Paul Barddal</em>, Heitor Murilo Gomes, and Fabrı́cio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the 30th Annual ACM Symposium on Applied Computing,
               Salamanca, Spain, April 13-17, 2015</em> --><div class="periodical">
            <em>In Proceedings of the 30th Annual ACM Symposium on Applied Computing,
               Salamanca, Spain, April 13-17, 2015</em> Apr 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/sncstream.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>Data Stream Clustering is an active area of research which requires efficient algorithms capable of finding and updating clusters incrementally. On top of that, due to the inherent evolving nature of data streams, it is expected that these algorithms manage to quickly adapt to both concept drifts and the appearance and disappearance of clusters. Nevertheless, many of the developed two-step algorithms are only capable of finding hyper-spherical clusters and are highly dependant on parametrization. In this paper we introduce SNCStream, a one-step online clustering algorithm based on Social Networks Theory, which uses homophily to find non-hyper-spherical clusters. Our empirical studies show that SNCStream is able to surpass density-based algorithms in cluster quality and requires feasible amount of resources (time and memory) when compared to other algorithms.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/sac/BarddalGE15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Barddal, Jean Paul and Gomes, Heitor Murilo and Enembreck, Fabr{\'{\i}}cio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SNCStream: a social network-based data stream clustering algorithm}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 30th Annual {ACM} Symposium on Applied Computing,
                 Salamanca, Spain, April 13-17, 2015}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{935--940}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/sac/2015}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/2695664.2695674}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/2695664.2695674}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Tue, 06 Nov 2018 11:06:47 +0100}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/sac/BarddalGE15}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
<li>
<!-- _layouts/bib.html -->
      <div class="row">
        <div class="col-sm-2 abbr"><abbr class="badge">SAC</abbr></div>

        <!-- Entry bib key -->
        <div id="DBLP:conf/sac/GomesBE15" class="col-sm-8">
        
          <!-- Title -->
          <div class="title">Pairwise combination of classifiers for ensemble learning on data
               streams</div>
          <!-- Author -->
          <div class="author">
          

          Heitor Murilo Gomes, <em>Jean Paul Barddal</em>, and Fabrı́cio Enembreck</div>

          <!-- Journal/Book title and date -->                    
          <!-- <em>In Proceedings of the 30th Annual ACM Symposium on Applied Computing,
               Salamanca, Spain, April 13-17, 2015</em> --><div class="periodical">
            <em>In Proceedings of the 30th Annual ACM Symposium on Applied Computing,
               Salamanca, Spain, April 13-17, 2015</em> Apr 2015
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
            <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a>
            <a href="/assets/pdf/pairwise_patterns.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a>
          </div>

          <!-- Hidden abstract block -->
          <div class="abstract hidden">
            <p>This work presents two different voting strategies for ensemble learning on data streams based on pairwise combination of component classifiers. Despite efforts to build a diverse ensemble, there is always some degree of overlap between component classifiers models. Our voting strategies are aimed at using these overlaps to support ensemble prediction. We hypothesize that by combining pairs of classifiers it is possible to alleviate incorrect individual predictions that would otherwise negatively impact the overall ensemble decision. The first strategy, Pairwise Accuracy (PA), combines the shared accuracy estimation of all possible pairs in the ensemble, while the second strategy, Pairwise Patterns (PP), record patterns of pairwise decisions during training and use these patterns during prediction. We present empirical results comparing ensemble classifiers with their original voting methods and our proposed methods in both real and synthetic datasets, with and without concept drifts. Our analysis indicates that pairwise voting is able to enhance overall performance for PP, especially on real datasets, and that PA is useful whenever there are noticeable differences in accuracy estimates among ensemble members, which is common during concept drifts.</p>
          </div>
<!-- Hidden bibtex block -->
          <div class="bibtex hidden">
            <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DBLP:conf/sac/GomesBE15</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gomes, Heitor Murilo and Barddal, Jean Paul and Enembreck, Fabr{\'{\i}}cio}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Pairwise combination of classifiers for ensemble learning on data
                 streams}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 30th Annual {ACM} Symposium on Applied Computing,
                 Salamanca, Spain, April 13-17, 2015}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{941--946}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span><span class="p">,</span>
  <span class="na">crossref</span> <span class="p">=</span> <span class="s">{DBLP:conf/sac/2015}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/2695664.2695754}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/2695664.2695754}</span><span class="p">,</span>
  <span class="na">timestamp</span> <span class="p">=</span> <span class="s">{Tue, 06 Nov 2018 11:06:46 +0100}</span><span class="p">,</span>
  <span class="na">biburl</span> <span class="p">=</span> <span class="s">{https://dblp.org/rec/bib/conf/sac/GomesBE15}</span><span class="p">,</span>
  <span class="na">bibsource</span> <span class="p">=</span> <span class="s">{dblp computer science bibliography, https://dblp.org}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure>
          </div>
        </div>
      </div>
</li>
</ol>


</div>

          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2022 Jean Paul Barddal. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-L588BBLF3F"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){ window.dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-L588BBLF3F');
  </script>
  </body>
</html>
