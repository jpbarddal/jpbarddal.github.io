<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Jean Paul Barddal | publications</title>
  <meta name="description" content="Just a simple page to let the world know about what is going on with my research. Based on [*folio](https://github.com/bogoli/-folio) design.
">


  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-136111924-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-136111924-1');
  </script>



  <!-- <link rel="shortcut icon" href="https://jpbarddal.github.io//assets/img/favicon.ico"> -->

  <!-- <link rel="stylesheet" href="https://jpbarddal.github.io//assets/css/main.css"> -->
  <!-- <link rel="canonical" href="https://jpbarddal.github.io//publications/"> -->


  <link rel="shortcut icon" href="/assets/img/favicon.ico">


  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/publications/">

</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Jean Paul</strong> Barddal
        <!-- <strong>JeanPaulBarddal</strong> -->
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <!-- <a class="page-link" href="https://jpbarddal.github.io//">about</a> -->
        <a class="page-link" href="/">about</a>

        <!-- Blog -->
        <!--
        <a class="page-link" href="https://jpbarddal.github.io//blog/">blog</a>
        -->

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <!-- <a class="page-link" href="https://jpbarddal.github.io//minicv/">mini cv</a> -->
            <a class="page-link" href="/minicv/">mini cv</a>
          
        
          
            <!-- <a class="page-link" href="https://jpbarddal.github.io//projects_and_data/">projects & data</a> -->
            <a class="page-link" href="/projects_and_data/">projects & data</a>
          
        
          
            <!-- <a class="page-link" href="https://jpbarddal.github.io//publications/">publications</a> -->
            <a class="page-link" href="/publications/">publications</a>
          
        
          
            <!-- <a class="page-link" href="https://jpbarddal.github.io//teaching/">teaching</a> -->
            <a class="page-link" href="/teaching/">teaching</a>
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="https://jpbarddal.github.io//assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">publications</h1>
    <h5 class="post-description">Sorted by year. This list is created using jekyll scholar. For an official publication list, please refer to my <a href="http://lattes.cnpq.br/5862618116527136">Lattes CV</a>.</h5>
  </header>

  <article class="post-content publications clearfix">
    
<h3 class="year">2022</h3>
<ol class="bibliography"><li>

<div id="SURVEY_PROCESS_MINING_DRIFT:2022">
  
    <span class="title">A Survey on Concept Drift in Process Mining</span>
    <span class="author">
      
        
          
            
              
                Sato, Denise Maria Vecino,
              
            
          
        
      
        
          
            
              
                Freitas, Sheila Cristiana,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Scalabrin, Edson Emilio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>ACM Computing Surveys</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/sato2021.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Concept drift in process mining (PM) is a challenge as classical
  methods assume processes are in a steady-state, i.e., events share the same
  process version. We conducted a systematic literature review on the
  intersection of these areas, and thus, we review concept drift in process
  mining and bring forward a taxonomy of existing techniques for drift
  detection and online process mining for evolving environments. Existing works
  depict that (i) PM still primarily focuses on offline analysis, and (ii) the
  assessment of concept drift techniques in processes is cumbersome due to the
  lack of common evaluation protocol, datasets, and metrics.</p>
  </span>
  
</div>
</li>
<li>

<div id="SMC_YEOJOHNSON:2022">
  
    <span class="title">Improving Data Stream Classification using Incremental Yeo-Johnson Power Transformation</span>
    <span class="author">
      
        
          
            
              
                Tieppo, Eduardo,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Nievola, Julio Cesar
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the IEEE Systems, Man, and Cybernetics Conference (IEEE SMC)</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/SMC22_YEOJOHNSON.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data transformation plays an essential role as a preprocessing
  step in learning models. Several classification techniques have premises about
  the underlying data distribution, such as normal distribution assumed in
  Bayesians classifiers. However, applying data transformation in a streaming
  setting requires processing an infinite and continuous flow of data. In this
  paper, we propose the Incremental Yeo-Johnson Power Transformation, a variant
  of the well-known batch Yeo-Johnson transformation that is tailored for
  streaming settings, i.e., it supports streaming data via statistical sampling
  and hypothesis testing. Experimental results show that our proposal achieves
  the same data normality as its batch counterpart. In addition, it improves
  the prediction performance of a data stream classifier based on Bayesian
  statistical models. Overall, learning models obtained 3 percentage points
  improvement.</p>
  </span>
  
</div>
</li>
<li>

<div id="ESANN_KRUGER:2022">
  
    <span class="title">A Machine Learning Approach for School Dropout Prediction in Brazil</span>
    <span class="author">
      
        
          
            
              
                Kruger, João Gabriel Corrêa,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Souza Britto Jr., Alceu
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 30th European Symposium on Artificial Neural Networks (ESANN)</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/XXX.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>School dropout is a severe problem that impacts many
               socio-economic aspects, including inequality. Dropout prediction
               algorithms can help remediate this problem, although several past
               attempts in the literature did so using datasets with small
               numbers of students. This paper brings forward an experimental
               approach of machine learning for school dropout prediction in
               Brazilian schools. The data used for this study was first
               retrieved from the academic systems of a group of Brazilian
               private schools, which was later enriched with socio-economic
               data extracted from governmental sources. Using the dataset to
               train different types of classifiers, we obtained precision
               scores of up to 95.2% when predicting dropout at different year
               moments and educational stages, thus allowing schools to plan and
               apply retention strategies.</p>
  </span>
  
</div>
</li>
<li>

<div id="IJCNN_CHDS:2022">
  
    <span class="title">Classifying Hierarchical Data Streams using Global Classifiers and Summarization Techniques</span>
    <span class="author">
      
        
          
            
              
                Tieppo, Eduardo,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Nievola, Julio Cesar
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2022 International Joint Conference on Neural Networks, IJCNN 2022,
               Padua, Italy, 2022</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/ijcnn_chds_2022.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The hierarchical classification of data streams requires models
               capable of handling a class hierarchy and updating themselves
               whenever a new example arrives, within restrained processing time
               and memory consumption. Current state-of-the-art models store raw
               instances and handle the hierarchy locally, performing a high
               number of computations at every hierarchy level and with all,
               eventually redundant, data. This paper introduces Global
               k-Nearest Centroids (kNC) and Global Dribble, two novel methods
               for the hierarchical classification of data streams. Both methods
               use summarization techniques to represent data with constant
               computational resources usage and a global classification
               approach to process instances in less time when compared to local
               strategies. We compare both methods with a state-of-the-art
               local classifier, and the proposed methods achieved a higher
               number of correct predictions and process instances nearly
               twice as fast.</p>
  </span>
  
</div>
</li>
<li>

<div id="IJCNN_FER:2022">
  
    <span class="title">Evaluation of Self-taught Learning-based Representations for Facial Emotion Recognition</span>
    <span class="author">
      
        
          
            
              
                Delazeri, Bruna,
              
            
          
        
      
        
          
            
              
                Veras, Leonardo Leon,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Koerich, Alessandro L.,
              
            
          
        
      
        
          
            
              
                and Souza Britto Jr., Alceu
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2022 International Joint Conference on Neural Networks, IJCNN 2022,
               Padua, Italy, 2022</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/ijcnn_fer_2022.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This work describes different strategies to generate unsupervised
               representations obtained through the concept of self-taught
               learning for facial emotion recognition (FER). The idea is to
               create complementary representations promoting diversity by
               varying the autoencoders’ initialization,  architecture, and
               training data. SVM, Bagging, Random Forest, and a dynamic
               ensemble selection method are evaluated as final classification
               methods. Experimental results on JAFFE and Cohn-Kanade datasets
               using a leave-one-subject-out protocol show that FER methods
               based on the proposed diverse representations compare favorably
               against state-of-the-art approaches that also explore unsupervised
               feature learning.</p>
  </span>
  
</div>
</li>
<li>

<div id="DIFOT_IJCNN:2022">
  
    <span class="title">Assessing Batch and Online Learning for Delivery in Full and On Time Predictions</span>
    <span class="author">
      
        
          
            
              
                Lima, Adriano Alves,
              
            
          
        
      
        
          
            
              
                Batista, Márcio Venâncio,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Sanches, Danilo Sipoli,
              
            
          
        
      
        
          
            
              
                and Oliveira, Luiz Eduardo Soares
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2022 International Joint Conference on Neural Networks, IJCNN 2022,
               Padua, Italy, 2022</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/ijcnn_difot_2022.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Improving results by optimizing process execution is one objective
               of major companies. For these corporations, the main point for
               achieving better results is the good maintenance of supply chain
               management. The most important supply chain metric is Delivery
               in Full and On Time (DIFOT). DIFOT measures how well a supply
               chain delivers value to the customer. In this work, we bring
               forward an analysis of DIFOT prediction from large Brazilian food
               company. More specifically, we compare a batch and online
               learning algorithm for DIFOT prediction and depict why the
               latter is suitable for this problem. Furthermore, we report a
               feature drift analysis to identify whether there are considerable
               shifts along with the dataset timespan. As a byproduct of this
               research, we make the dataset used in this analysis publicly
               available for future research in DIFOT prediction.</p>
  </span>
  
</div>
</li>
<li>

<div id="ESWA_PKLOT_SURVEY:2022">
  
    <span class="title">A Systematic Review on Computer Vision-Based Parking Lot Management Applied on Public Datasets</span>
    <span class="author">
      
        
          
            
              
                Almeida, Paulo Ricardo Lisboa,
              
            
          
        
      
        
          
            
              
                Alves, Jeovane Honório,
              
            
          
        
      
        
          
            
              
                Parpinelli, Rafael Stubs,
              
            
          
        
      
        
          
            
              
                and Barddal, Jean Paul
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Expert Systems with Applications</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/draft_pklot_survey2022.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Computer vision-based parking lot management methods have been extensively
  researched upon owing to their flexibility and cost-effectiveness. To evaluate such
  methods authors often employ publicly available parking lot image datasets. In this
  study, we surveyed and compared robust publicly available image datasets specifically
  crafted to test computer vision-based methods for parking lot management approaches and
  consequently present a systematic and comprehensive review of existing works that employ
  such datasets. The literature review identified relevant gaps that require further research,
  such as the requirement of dataset-independent approaches and methods suitable for autonomous
  detection of position of parking spaces. In addition, we have noticed that several important
  factors such as the presence of the same cars across consecutive images, have been neglected
  in most studies, thereby rendering unrealistic assessment protocols. Furthermore, the analysis
  of the datasets also revealed that certain features that should be present when developing new
  benchmarks, such as the availability of video sequences and images taken in more diverse conditions,
  including nighttime and snow, have not been incorporated.</p>
  </span>
  
</div>
</li>
<li>

<div id="TIEPPO_KNC_DRIBBLE">
  
    <span class="title">Univariate Time Series Prediction Using Data Stream Mining Algorithms and Temporal Dependence</span>
    <span class="author">
      
        
          
            
              
                Mochinski, Marcos Alberto,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabricio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of International Conference on Agents and Artificial Intelligence,
               ICAART 2022</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/ICAART_2022_165.pdf" target="_blank">PDF</a>]
  
  
  
  
  
    [<a href="www.google.com" target="_blank">Source code</a>]
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In this paper, we present an exploratory study conducted to
  evaluate the impact of temporal dependence modeling on time series forecasting
  with Data Stream Mining (DSM) techniques. DSM algorithms have been used
  successfully in many domains that exhibit continuous generation of
  non-stationary data. However, the use of DSM in time series is rare since they
   usually are univariate and exhibit strong temporal dependence.
  This is the main motivation for this work, such that this study mitigates such
  gap by presenting a univariate time series prediction method based on AdaGrad
  (a DSM algorithm), Auto.Arima (a statistical method) and features extracted
  from adjusted autocorrelation function (ACF) coefficients. The proposed method
  uses adjusted ACF features to convert the original series observations into
  multivariate data, executes the fitting process using the DSM and the
  statistical algorithm, and combines the AdaGrad’s and Auto.Arima’s forecasts
  to establish the final predictions for each time series. Experiments conducted
  with five datasets containing 141,558 time series resulted in up to 12.429%
  improvements in sMAPE (Symmetric Mean Average Percentage Error) error rates
  when compared to Auto.Arima. The results depict that combining DSM with ACF
  features and statistical time series methods is a suitable approach for
  univariate forecasting.</p>
  </span>
  
</div>
</li>
<li>

<div id="TIEPPO_KNC_DRIBBLF">
  
    <span class="title">Automatic Disease Vector Mosquitoes Identification via Hierarchical Data Stream Classification</span>
    <span class="author">
      
        
          
            
              
                Tieppo, Eduardo,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Nievola, Julio Cesar
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the Annual ACM Symposium on Applied Computing,
               SAC 2022</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/SAC_2022_KNC_DRIBBLE.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Vector-borne diseases (VBDs), such as Dengue or Malaria, are one of the main concerns of public health agencies and governments.
  These diseases are mainly spread by mosquitoes acting as vectors by transmitting infected blood between humans.
  Machine learning can be used to design and improve control strategies of VBDs by providing models able to recognize disease vector mosquitoes and automatically capture or kill harmful species.
  The automatic identification of disease vector mosquitoes was not yet addressed concerning the hierarchical classification of data streams.
  Thus, reliable information has not been used to improve learning models, such as mosquitoes’ hierarchical taxonomy.
  In this study, we propose a framework for the automatic identification of disease vector mosquitoes in the context of the hierarchical classification of data streams area.
  To this end, we propose a hierarchical adaptation of a disease vector mosquitoes’ dataset to include their taxonomy and introduce kNC and Dribble, two novel classification methods fitted to hierarchical data streams representing the mosquitoes.
  Results depicted that our framework, using summarization techniques, achieves significantly better prediction and processing speed rates when compared to existing state-of-the-art models.</p>
  </span>
  
</div>
</li>
<li>

<div id="SMC_PATTERN_SPOTTING:2022">
  
    <span class="title">Pattern Spotting and Image Retrieval in Historical Documents using Deep Hashing</span>
    <span class="author">
      
        
          
            
              
                Silva Dias, Caio,
              
            
          
        
      
        
          
            
              
                Souza Britto Jr., Alceu,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Heutte, Laurent,
              
            
          
        
      
        
          
            
              
                and Koerich, Alessandro Lameiras
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the IEEE Systems, Man, and Cybernetics Conference (IEEE SMC)</em>
    
    
      2022
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/SMC22_YEOJOHNSON.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This paper presents a deep learning approach for image retrieval
  and pattern spotting in digital collections of historical documents. First, a
  region proposal algorithm detects object candidates in the document page
  images. Next, deep learning models are used for feature extraction,
  considering two distinct variants, which provide either real-valued or binary
  code representations. Finally, candidate images are ranked by computing the
  feature similarity with a given input query. A robust experimental protocol
  evaluates the proposed approach considering each representation scheme
  (real-valued and binary code) on the DocExplore image database. The
  experimental results show that the proposed deep models compare favorably to
  the state-of-the-art image retrieval approaches for images of historical
  documents, outperforming other deep models by 2.56 percentage points using
  the same techniques for pattern spotting. Besides, the proposed approach also
  reduces the search time up to 200x, and the storage cost up to
  6,000x when compared to related works based on real-valued
  representations.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2021</h3>
<ol class="bibliography"><li>

<div id="BARDDAL_ICPR:2021">
  
    <span class="title">Classifier Pool Generation based on a Two-level Diversity Approach</span>
    <span class="author">
      
        
          
            
              
                Monteiro, Marcos,
              
            
          
        
      
        
          
            
              
                Souza Britto Jr, Alceu,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Oliveira, Luiz Soares,
              
            
          
        
      
        
          
            
              
                and Sabourin, Robert
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In International Conference on Pattern Recognition (ICPR)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/classifier_pool_two_level.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This paper describes a classifier pool generation method
  guided by the diversity estimated on the data complexity and classifier
  decisions. First, the behavior of complexity measures is assessed by
  considering several subsamples of the dataset. The complexity measures
  with high variability across the subsamples are selected for posterior
  pool adaptation, where an evolutionary algorithm optimizes diversity in
  both complexity and decision spaces. A robust experimental protocol with
  28 datasets and 20 replications is used to evaluate the proposed method.
  Results show significant accuracy improvements in 69.4% of the experiments
  when Dynamic Classifier Selection and Dynamic Ensemble Selection methods
  are applied.  </p>
  </span>
  
</div>
</li>
<li>

<div id="TIEPPO_SLR:2021">
  
    <span class="title">Hierarchical classification of data streams: a systematic literature review</span>
    <span class="author">
      
        
          
            
              
                Tieppo, Eduardo,
              
            
          
        
      
        
          
            
              
                Santos, Roger Robson,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Nievola, Júlio Cesar
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Artificial Intelligence Review</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/tieppo_survey.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The classification task usually works with flat and batch learners,
  assuming problems as stationary and without relations between class labels.
  Nevertheless, several real-world problems do not assume these premises, i.e.,
  data have labels organized hierarchically and are made available in streaming
  fashion, meaning that their behavior can drift over time. Existing studies on
  hierarchical classification do not consider data streams as input of their process,
  and thus, data is assumed as stationary and handled through batch learners. The same
  can be said about works on streaming data, as the hierarchical classification is
  overlooked. Studies concerning each area individually are promising, yet, do not
  tackle their intersection. This study analyzes the main characteristics of the
  state-of-the-art works on hierarchical classification for streaming data concerning
  five aspects: (i) problems tackled, (ii) datasets, (iii) algorithms, (iv) evaluation
  metrics, and (v) research gaps in the area. We performed a systematic literature
  review of primary studies and retrieved 3,722 papers, of which 42 were identified
  as relevant and used to answer the aforementioned research questions.
  We found that the problems handled by hierarchical classification of data streams
  include mainly classification of images, human activities, texts, and audio; the
  datasets are mostly created or synthetic data; the algorithms and evaluation metrics
  are well-known techniques or based on those; and research gaps are related to dynamic
  context, data complexity, and computational resources constraints.
  We also provide implications for future research and experiments to consider common
  characteristics shared amongst hierarchical classification and data stream classification.</p>
  </span>
  
</div>
</li>
<li>

<div id="TIEPPO_BRACIS:2021">
  
    <span class="title">Classifying Potentially Unbounded Hierarchical Data Streams with Incremental Gaussian Naive Bayes</span>
    <span class="author">
      
        
          
            
              
                Tieppo, Eduardo,
              
            
          
        
      
        
          
            
              
                Nievola, Julio Cesar,
              
            
          
        
      
        
          
            
              
                and Barddal, Jean Paul
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Brazilian Conference on Intelligent System (BRACIS)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/bracis_tieppo.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Hierarchical Classification of Data Streams inherits the properties
  and constraints of Hierarchical Classification and Data Stream Classification
  areas concomitantly. Therefore, it requires novel approaches that (i) can handle
  class hierarchies, (ii) can be updated over time, and (iii) are computationally
  light-weighted regarding processing time and memory usage. In this study, we
  propose the <i>Gaussian Naive Bayes for Hierarchical Data Streams</i> (GNB-hDS)
  method: an incremental Gaussian Naive Bayes for classifying potentially unbounded
  hierarchical data streams. The GNB-hDS method uses statistical summaries of the
  data stream instead of storing actual instances. These statistical summaries allow
  more efficient data storage, maintain constant computational time and memory, and
  calculate the probability of an instance belonging to a specific class via the
  Bayes’ Theorem. We compare our method against a technique that stores raw instances,
  and results show that our method obtains equivalent prediction rates while being
  statistically faster.</p>
  </span>
  
</div>
</li>
<li>

<div id="TIEPPO_SMC:2021">
  
    <span class="title">Adaptive Global k-Nearest Neighbors for Hierarchical Classification of Data Streams</span>
    <span class="author">
      
        
          
            
              
                Tieppo, Eduardo,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Nievola, Julio Cesar
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In IEEE Conference on Systems, Man, and Cybernetics (SMC)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/smc_globalknn.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data stream classification differs from batch learning classification methods as data is made available sequentially and may drift over time. Therefore, data stream classification can be simultaneous to all other kinds of classification problems, and it has been revisiting many aspects related to classification in the last years. So far, hierarchical classification was weakly addressed in streaming scenarios despite being a well-established research topic. In this paper, we propose the adaptive global k-Nearest Neighbors for hierarchical classification of data streams (Global kNN-hDS). Our proposal is able to classify hierarchical data streams using a constrained memory buffer and following a global approach. We compare our method against a local kNN also tailored for streaming scenarios, and results show that our method obtains competitive prediction rates while being statistically faster.</p>
  </span>
  
</div>
</li>
<li>

<div id="LUCCA1_IJCNN:2021">
  
    <span class="title">Dynamically Selected Ensemble for Data Stream Classification</span>
    <span class="author">
      
        
          
            
              
                Cavalheiro, Lucca Portes,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Souza Britto Jr., Alceu,
              
            
          
        
      
        
          
            
              
                and Heutte, Laurent
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In International Joint Conference on Neural Networks (IJCNN)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/ddcs.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Mining data streams is a hot topic in the machine learning (ML) community.
  In addition to learning and updating accurate models over time, these techniques must
  respect constraints that are not necessarily as strong in batch mode, such as time processing
  and memory consumption efficiency. A successful family of techniques in batch ML is dynamic
  classifier selection (DCS). However, these are roughly overlooked in data stream mining.
  In this paper, we propose a novel dynamic classifier selection framework for data streams
  called Double Dynamic Classifier Selection (DDCS). We compare DDCS against state-of-art methods
  for mining data streams in both synthetic and real-world datasets. Results depict that DDCS not
  only outperforms the state-of-art ensemble methods for data stream classification in terms of
  accuracy but is also significantly more efficient in terms of processing time and memory consumption.</p>
  </span>
  
</div>
</li>
<li>

<div id="LUCCA2_IJCNN:2021">
  
    <span class="title">Towards the Overcome of Performance Pitfalls in Data Stream Mining Tools</span>
    <span class="author">
      
        
          
            
              
                Cavalheiro, Lucca Portes,
              
            
          
        
      
        
          
            
              
                Zanata, Marco Antonio Alves,
              
            
          
        
      
        
          
            
              
                and Barddal, Jean Paul
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In International Joint Conference on Neural Networks (IJCNN)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/lucca_pitfalls.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data stream mining is an essential task in today’s scientific community.
  It allows machine learning models to be updated over time as new data becomes available.
  Three pillars should be accounted for when selecting an appropriate algorithm for data stream mining: accuracy, processing time, and memory consumption.
  To develop and assess machine learning models in streaming scenarios, different tools have been developed, where the Massive Online Analysis, written in Java, and scikit-multiflow, written in Python, are in the spotlight.
  Despite the ease of use of both tools, neither are focused on performance, which puts in jeopardy the usage of the computational resources.
  In this paper, we show that with the right tools, Python libraries reach performance comparable to C/C++.
  More specifically, we show how optimized implementations in scikit-multiflow using low-level languages, i.e., C++, C++ with Intel Intrinsics, and Rust; with bindings to Python vastly overcome existing tools in computational resources usage while keeping predictive performance intact.</p>
  </span>
  
</div>
</li>
<li>

<div id="DENISE:2021">
  
    <span class="title">Interactive Process Drift Detection Framework</span>
    <span class="author">
      
        
          
            
              
                Sato, Denise Maria Vecino,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Scalabrin, Edson Emilio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In International Conference on Artificial Intelligence and Soft Computing (ICAISC)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/ipdd.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This paper presents a novel tool for detecting drifts in process models.
  The tool targets the challenge of defining the better parameter configuration for detecting
  drifts by providing an interactive user interface. Using this interface, the user can quickly
  change the parameters and verify how the process evolved. The process evolution is presented
  in a timeline of process models, simulating a “replay” of models over time. One instantiation
  of the framework was implemented using a fixed-size sliding window, discovering process maps
  using directly-follows graphs (DFGs), and calculating nodes and edges similarities. This instantiation
  was evaluated using a benchmarking dataset of simple and complex drift patterns. The tool correctly
  detected 17 from the 18 change patterns, thus confirming its potential when an adequate window size
  is set. The user interface shows that replaying the process models provides a visual understanding of
  the changing process. The concept drift is explained by the similarity metrics’ differences, thus
  allowing drift localization. </p>
  </span>
  
</div>
</li>
<li>

<div id="ESWA_SUPERMARKET:2021">
  
    <span class="title">A case study of batch and incremental recommender systems in supermarket data under concept drifts and cold start</span>
    <span class="author">
      
        
          
            
              
                Viniski, Antônio David,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Souza Britto Jr., Alceu,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabricio,
              
            
          
        
      
        
          
            
              
                and Campos, Humberto Vinicius Aparecido
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Expert Systems with Applications</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/case_study_recsys.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Recommender systems uncover relationships between users and items, thus allowing personalized recommendations.
            Nonetheless, users’ preferences may change over time, the so-called concept drifts; or new users and items may appear,
            making the recommender system unable to accurately map the relationship between users and items due to the cold start problem.
            Consequently, concept drift and cold start are challenges that downgrade the recommender system’s predictive performance.
            This paper assesses existing approaches for collaborative-filtering recommender systems over a real supermarket dataset that
            exhibits both of the issues mentioned above.
            For this purpose, our comparative analysis encompasses batch and streaming learning approaches.
            As a result, we can observe that streaming-based models achieve better recommendation rates since these are tailored to fit the concept drift.
            More specifically, the predictive performance of streaming-based recommendations increases by up to 21% over those provided by batch methods.
            The supermarket dataset used in experimentation is also made publicly available for future studies and recommender systems comparisons.</p>
  </span>
  
</div>
</li>
<li>

<div id="BARDDAL_PAKDD:2021">
  
    <span class="title">UKIRF: An Item Rejection Framework for Improving Negative Items Sampling in One-Class Collaborative Filtering</span>
    <span class="author">
      
        
          
            
              
                Viniski, Antônio David,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Souza Britto Jr., Alceu
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD)</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/ukirf.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Collaborative Filtering (CF) is one of the most successful techniques in recommender systems.
               Most CF scenarios depict positive-only implicit feedback, which means that negative feedback is unavailable.
               Therefore, One-Class Collaborative Filtering (OCCF) techniques have been tailored to tackling these scenarios.
               Nonetheless, several OCCF models still require negative observations during training, and thus, a popular approach
               is to consider randomly selected unknown relationships as negative.
               In this work, we bring forward a novel approach for selecting negative items called Unknown Item Rejection Framework (UKIRF).
               More specifically, we instantiate UKIRF using similarity approaches, i.e., TF-IDF and Cosine, to reject items that are similar
               to those a user interacted with. We apply UKIRF to different OCCF models in different datasets and show that it improves the
               recall rates up to 24% when compared to random sampling. </p>
  </span>
  
</div>
</li>
<li>

<div id="SATO_ICPM:2021">
  
    <span class="title">Interactive Process Drift Detection: a framework for visual analysis of process drifts</span>
    <span class="author">
      
        
          
            
              
                Sato, Denise Maria Vecino,
              
            
          
        
      
        
          
            
              
                Fontana, Rafaela Mantovani,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Scalabrin, Edson Emilio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In International Conference on Process Mining (ICPM) - Demo track</em>
    
    
      2021
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/L-Interactive-Process-Drift-Detection-A-Framework-for-Visual-Analysis-of-Process-Drifts.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Interactive Process Drift Detection (IPDD) is a framework for visual analysis of
  process drifts. A process drift indicates a change in the process model occurred at some point
  in time. IPDD approach firstly generates process models for subparts of the event log using a
  sliding window approach. Then, IPDD detects the drifts by evaluating similarity metrics calculated
  between adjacent process models; a difference in some of the metrics indicates a drift. The current
  implementation of IPDD generates the process models using the directly-follows graph and applies two
  similarity metrics: nodes and edges similarity. The user interface shows the drifts in the process
  models over time, allowing the user to visually understand the model changes. Also, the user can easily
  change the hyperparameters for the drift analysis and verify the results on the interface. The user
  interface of IPDD also allows the user to evaluate the detected drifts by calculating the F-score metrics,
  which is useful when using artificial datasets. The underlying idea is to ease the choice of a "good"
  value for the hyperparameter configuration, which is critical for almost any drift detection mechanism.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2020</h3>
<ol class="bibliography"><li>

<div id="Obladen2019">
  
    <span class="title">ANÁLISE PREDITIVA E DECISÕES JUDICIAIS: controvérsia ou realidade?</span>
    <span class="author">
      
        
          
            
              
                Almendra Freitas, Cinthia Obladen,
              
            
          
        
      
        
          
            
              
                and Barddal, Jean Paul
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Revista Democracia Digital e Governo Eletrônico</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/obladen_2020.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>In this paper, we provide an overview of how Data Analytics, Big Data, and Machine Learning may assist the judicial system by providing insightful information to citizens, police, lawyers, and judges, in a fast and accurate way. We conduct a bidirectional analysis between Law and Predictive Analytics applying the deductive method and bibliographic technique. We report concerns that Law should have with the application of computational techniques in different scenarios, mainly in the judicial system. Finally, we bring forward controversies between these areas, such as the new companies that target the use of personal and sensitive data in Law applications, and how these are potentially hurting fundamental rights and leading to biases in critical systems, wuch as predictive systems for crime recidivism.</p>
  </span>
  
</div>
</li>
<li>

<div id="BARDDAL_SMC2_2020">
  
    <span class="title">Naïve Approaches to Deal with Concept Drifts </span>
    <span class="author">
      
        
          
            
              
                Almeida, Alceu Souza Britto Jr,
              
            
          
        
      
        
          
            
              
                and Barddal, Jean Paul
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/naive_approaches_concept_drift.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>A common problem in machine learning is to find
representative real-world problems to put the methods to
test. When developing approaches to deal with concept
drifts, some datasets such as the Forest Covertype and
Nebraska Weather are a common choice for testing. We argue
that some well-known real-world concept drift datasets
present a high serial dependence in the target class and
may have only minor changes. With this in mind, we propose
the use of naïve methods that should be used for
comparison with methods that deal with concept drifts. The
experimental results using six real-world well-known
concept drift datasets show that the naïve
approaches can be better than some methods to deal with
possible concept drifts in datasets such as the Forest
Covertype, Electricity, and Nebraska Weather. These results
suggest that some widely used datasets may be trivial from
the concept drift standpoint, and thus, should be avoided
or at least the results should be compared with the
proposed naïve methods.</p>
  </span>
  
</div>
</li>
<li>

<div id="BARDDAL_SMC3_2020">
  
    <span class="title">Improving Multiple Time Series Forecasting with Data Stream Mining Algorithms  </span>
    <span class="author">
      
        
          
            
              
                Marcos Alberto Mochinski, Jean Paul Barddal,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabricio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/multiple_time_series.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This paper proposes a hybrid ensemble learning approach
that combines statistical and data stream mining algorithms
to obtain better forecasting performance in multiple time
series prediction problems. Although some multiple time
series algorithms perform surprisingly well in a variety of
domains, it is well-known that no one is dominant for every
existent domain. Therefore, we developed a meta-technique
based on data stream mining and static ensemble selection
strategy and evaluated its forecasting goodness-of-fit in
time series datasets from M3 and M4 competitions. After
training different regression models, we show how the
combination of auto.arima and AdaGrad lead to improved
forecasting rates, thus surpassing the results of
state-of-art algorithms.</p>
  </span>
  
</div>
</li>
<li>

<div id="BARDDAL_SMC4_2020">
  
    <span class="title">ADADRIFT: An Adaptive Learning Technique for Long-History Stream-Based Recommender Systems  </span>
    <span class="author">
      
        
          
            
              
                Eduardo Ferreira José, Fabricio Enembreck,
              
            
          
        
      
        
          
            
              
                and Barddal, Jean Paul
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/adadrift.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Adaptive recommender systems are increasingly showing their
importance as profiling is a dynamic problem. Their goal is
to update recommendation models as new interactions take
place, thus swiftly adapting to drifts in the user’s
behavior and desires, and item’s audience. However,
existing recommendation algorithms usually do not perform
well during drifts, as they take long to adapt to changes,
or these updates are suboptimal since they account for all
profiles’ preferences equally, which is often untrue as
each individual and its changes are unique. In this paper,
we propose the ADADRIFT algorithm to deal with user and
item-based drifts in adaptive recommender systems using
personalized learning rates based on profile statistics.
The experiments using stream-based recommender systems
(ISGD and BRISMF) across four different datasets show that
ADADRIFT surpasses ADADELTA with significant improvements
in recommendation rates. The best results appear when the
data streams have a long history of the users’ or items’
interactions and drifts become noticeable. The
experimentation in this work highlight the importance of
handling drifts in recommender systems. </p>
  </span>
  
</div>
</li>
<li>

<div id="BARDDAL_LESSONS_LEARNED:2020">
  
    <span class="title">Lessons learned from data stream classification applied to credit scoring</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Loezer, Lucas,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabrício,
              
            
          
        
      
        
          
            
              
                and Lanzuolo, Riccardo
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Expert Systems with Applications</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/lessons_credit_scoring.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The financial credibility of a person is a factor used to determine whether a loan should be approved or not, and this is quantified by a ‘credit score,’ which is calculated using a variety of factors, including past performance on debt obligations, profiling, amongst others. Machine learning has been widely applied to automate the development of effective credit scoring models over the years. Yet, studies show that the development of robust credit scoring models may take longer than a year, and thus, if the behavior of customers changes over time, the model will be outdated even before its deployment. In this paper, we made 3 anonymized real-world credit scoring datasets available alongside the results obtained. In each of these datasets, we verify whether the credit scoring task should be thought as an ephemeral scenario since many of the variables may drift over time, and thus, data stream mining techniques should be used since they were tailored for incremental learning and to detect and adapt to changes in the data distribution. Therefore, we compare both traditional batch machine learning algorithms with data stream algorithms in different validation schemes using both Kolmogorov–Smirnov and Population Stability Index metrics. Furthermore, we also provide insights on the importance of features according to their Information Value, Mean Decrease Impurity, and Mean Positional Gain metrics, such that the last depicts changes in the importance of features over time. For 2 of the 3 tested datasets, the results obtained by data stream learners are comparable to predictive models currently in use, thus showing the efficiency of data stream classification for the credit scoring task.</p>
  </span>
  
</div>
</li>
<li>

<div id="Barddal_Enembreck:2020">
  
    <span class="title">Regularized and incremental decision trees for data streams</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabricio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Annals of Telecommunications</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/regularized_ht.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Decision trees are a widely used family of methods for learning predictive models from both batch and streaming data. Despite depicting positive results in a multitude of applications, incremental decision trees continuously grow in terms of nodes as new data becomes available, i.e., they eventually split on all features available, and also multiple times using the same feature; thus leading to unnecessary complexity and overfitting. With this behavior, incremental trees lose the ability to generalize well, be human-understandable and computationally efficient. To tackle these issues, we proposed in a previous study a regularization scheme for Hoeffding decision trees that: (i) uses a penalty factor to control the gain obtained by creating a new split node using a feature that has not been used thus far; and (ii) uses information from previous splits in the current branch to determine whether the gain observed indeed justifies a new split. In this paper, we extend this analysis and apply the proposed regularization scheme to other types of incremental decision trees and report the results in both synthetic and real-world scenarios. The main interest is to verify whether and how the proposed regularization scheme affects the different types of incremental trees. Results show that in addition to the original Hoeffding Tree, the Adaptive Random Forest also benefits from regularization, yet, McDiarmid Trees and Extremely Fast Decision trees observe declines in accuracy.</p>
  </span>
  
</div>
</li>
<li>

<div id="Hochuli2020">
  
    <span class="title">An End-to-End Approach for Recognition of Modern and Historical Handwritten Numeral Strings</span>
    <span class="author">
      
        
          
            
              
                Hochuli, André Gustavo,
              
            
          
        
      
        
          
            
              
                Souza Britto Jr., Alceu,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Oliveira, Luiz Eduardo Soares,
              
            
          
        
      
        
          
            
              
                and Sabourin, Robert
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 2020 International Joint Conference on Neural Networks (IJCNN)
               Glasgow, Scotland</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/end2end_hochuli.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>An end-to-end solution for handwritten numeral string recognition is proposed, in which the numeral string is considered as composed of objects automatically detected and recognized by a YoLo-based model. The main contribution of this paper is to avoid heuristic-based methods for string preprocessing and segmentation, the need for task-oriented classifiers, and also the use of specific constraints related to the string length. A robust experimental protocol based on several numeral string datasets, including one composed of historical documents, has shown that the proposed method is a feasible end-to-end solution for numeral string recognition. Besides, it reduces the complexity of the string recognition task considerably since it drops out classical steps, in special preprocessing, segmentation, and a set of classifiers devoted to strings with a specific length.</p>
  </span>
  
</div>
</li>
<li>

<div id="Loezer2020">
  
    <span class="title">Cost-sensitive learning for imbalanced data streams</span>
    <span class="author">
      
        
          
            
              
                Loezer, Lucas,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabricio,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Souza Britto Jr., Alceu
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 34rd Annual ACM Symposium on Applied Computing,
               SAC 2020, Brno, Czech Republic, March 30 - April 3, 2020</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/loezer2020.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The data imbalance problem hampers the classification task. In streaming environments, this becomes even more cumbersome as the proportion of classes can vary over time. Approaches based on misclassification costs can be used to mitigate this problem. In this paper, we present the Cost-sensitive Adaptive Random Forest (CSARF) and compare it to the Adaptive Random Forest (ARF) and ARF with Resampling (ARF_RE) in six real-world and six synthetic data sets with different class ratios. The empirical study analyzes two misclassification costs strategies of the CSARF and shows that the CSARF obtained statistically superior w.r.t. the average recall and average F1 when compared to ARF.</p>
  </span>
  
</div>
</li>
<li>

<div id="BARDDAL_SMC1_2020">
  
    <span class="title">Combining Slow and Fast Learning for Improved Credit Scoring  </span>
    <span class="author">
      
        
          
            
              
                Jean Paul Barddal, Lucas Loezer,
              
            
          
        
      
        
          
            
              
                and Lanzuolo, Riccardo
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In IEEE International Conference on Systems, Man, and Cybernetics (IEEE SMC)</em>
    
    
      2020
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/combined_slow_fast_credit_scoring.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The financial credibility of a person is a relevant factor
to determine whether a loan should be approved or not, and
it is quantified by a credit score, which is computed using
past performance on debt obligations, profiling, and other
data available.
Credit scoring becomes even a hotter topic in emerging
countries, as interest rates and customer behavior swiftly
vary, given the economic (in)stability of the country and
as fintechs are chasing robust solutions for improved
credit scoring solutions.
Batch machine learning is often deployed for credit
scoring, yet, they are tailored for static scenarios, i.e.,
they are not prepared to swiftly detect and adapt to
changes in customer behavior, thus leading to slow recovery
in such scenarios.
In this paper, we bring forward an analysis on how batch
machine learning can be combined with data stream mining
techniques, thus leading to better recognition rates in
credit scoring scenarios.
We analyze three different real-world datasets from
Brazilian financial institutions, whilst keeping their
secrecy preserved, and show how batch and stream learning
can be combined towards improved credit scoring systems, as
well as highlighting relevant gaps that still require
attention.  </p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2019</h3>
<ol class="bibliography"><li>

<div id="Gomes2019">
  
    <span class="title">Machine learning for streaming data</span>
    <span class="author">
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Read, Jesse,
              
            
          
        
      
        
          
            
              
                Bifet, Albert,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Gama, João
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>ACM SIGKDD Explorations Newsletter</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/sigkdd.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Incremental learning, online learning, and data stream learning are terms commonly associated with learning algorithms that update their models given a continuous influx of data without performing multiple passes over data. Several works have been devoted to this area, either directly or indirectly as characteristics of big data processing, i.e., Velocity and Volume. Given the current industry needs, there are many challenges to be addressed before existing methods can be efficiently applied to real-world problems. In this work, we focus on elucidating the connections among the current state-of-the-art on related fields; and clarifying open challenges in both academia and industry. We treat with special care topics that were not thoroughly investigated in past position and survey papers. This work aims to evoke discussion and elucidate the current research opportunities, highlighting the relationship of different subareas and suggesting courses of action when possible.</p>
  </span>
  
</div>
</li>
<li>

<div id="JOURNAL_FRANKIE">
  
    <span class="title">Addressing Feature Drift in Data Streams Using Iterative Subset Selection</span>
    <span class="author">
      
        
          
            
              
                Yuan, Lanqin,
              
            
          
        
      
        
          
            
              
                Pfahringer, Bernhard,
              
            
          
        
      
        
          
            
              
                and Barddal, Jean Paul
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>SIGAPP Appl. Comput. Rev.</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/lanqin_journal.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data streams are prone to various forms of concept drift over time including, for instance, changes to the relevance of features. This specific kind of drift is known as feature drift and requires techniques tailored not only to determine which features are the most important but also to take advantage of them. Feature selection has been studied and shown to improve classifier performance in standard batch data mining, yet it is mostly unexplored in data stream mining. This paper presents a novel method of feature subset selection specialized for dealing with the occurrence of feature drifts called Iterative Subset Selection (ISS), which splits the feature selection process into two stages by first ranking the features using some scoring function, and then iteratively selecting feature subsets using this ranking. This work further extends upon our prior work by exploring feeding information from the subset selection stage back into the ranking process. Applying our method to the Naïve Bayes and k-Nearest Neighbour classifier, we obtain compelling accuracy improvements when compared to existing works.</p>
  </span>
  
</div>
</li>
<li>

<div id="VHPRE">
  
    <span class="title">Vertical and Horizontal Partitioning in Data Stream Regression Ensembles</span>
    <span class="author">
      
        
          
            Barddal, Jean Paul
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2019 International Joint Conference on Neural Networks, IJCNN 2019,
               Budapest, Hungary, July 14-19, 2019</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/vertical_horizontal_regression.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data stream mining is an emerging topic in machine learning that targets the creation and update of predictive models over time as new data becomes available. Regarding existing works, classification is the most widely tackled task, which leaves regression nearly untouched. In this paper, the focus relies on ensemble learning for data stream regression, more specifically on vertical and horizontal data partitioning techniques. The goal is to determine whether and under which conditions partitioning can lessen the error rates of different types of learners in the data stream regression task. The proposed method combines vertical and horizontal partitioning, and it is compared with and against different types of learners and existing ensembles.</p>
  </span>
  
</div>
</li>
<li>

<div id="REGULARIZED_HTS">
  
    <span class="title">Learning Regularized Hoeffding Trees from Data Streams</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabricio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 34rd Annual ACM Symposium on Applied Computing,
               SAC 2019, Limassol, Cyprus, April 08-12, 2019</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/regularized_ht_sac.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Learning from data streams is a hot topic in machine learning that targets the learning and update of predictive models as data becomes available for both training and query. Due to their simplicity and convincing results in a multitude of applications, Hoeffding Trees are, by far, the most widely used family of methods for learning decision trees from streaming data. Despite the aforementioned positive characteristics, Hoeffding Trees tend to continuously grow in terms of nodes as new data becomes available, i.e., they eventually split on all features available, and multiple times on the same feature; thus leading to unnecessary complexity. With this behavior, Hoeffding Trees lose the ability to be human-understandable and computationally efficient. To tackle these issues, we propose a regularization scheme for Hoeffding Trees that (i) uses a penalty factor to control the gain obtained by creating a new split node using a feature that has not been used thus far; and (ii) uses information from previous splits in the current branch to determine whether the gain observed indeed justifies a new split. The proposed scheme is combined with both standard and adaptive variants of Hoeffding Trees. Experiments using real-world, stationary and drifting synthetic data show that the proposed method prevents both original and adaptive Hoeffding Trees from unnecessarily growing while maintaining impressive accuracy rates. As a byproduct of the regularization process, significant improvements in processing time, model complexity, and memory consumption have also been observed, thus showing the effectiveness of the proposed regularization scheme.</p>
  </span>
  
</div>
</li>
<li>

<div id="KARAX_TREE_FEATURE_IMPORTANCE">
  
    <span class="title">Decision tree-based Feature Ranking in Concept Drifting Data Streams</span>
    <span class="author">
      
        
          
            
              
                Jean Antonio Karax, Andreia Malucelli,
              
            
          
        
      
        
          
            
              
                and Barddal, Jean Paul
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 34rd Annual ACM Symposium on Applied Computing,
               SAC 2019, Limassol, Cyprus, April 08-12, 2019</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/karax2019.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data stream mining targets the learning of predictive models that evolve over time according to changes in arriving data. Throughout the years, several approaches have been tailored to create and continuously update predictive models from these streams, and from these, Hoeffding Trees became a popular choice for learning decision trees from data streams. In this paper, we aim at quantifying and expressing the importance of features in dynamic scenarios is of the utmost importance as they allow domain experts to back up, or invalidate, a predictive model. Therefore, we propose and assess a positional gain method tailored for for both individual and ensembles of Hoeffding Trees and how these behave in both synthetic and real-world scenarios.</p>
  </span>
  
</div>
</li>
<li>

<div id="BARDDAL201913">
  
    <span class="title">Boosting decision stumps for dynamic feature selection on data streams</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabrício,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Bifet, Albert,
              
            
          
        
      
        
          
            
              
                and Pfahringer, Bernhard
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Information Systems</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/boostingdecisionstumps.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Feature selection targets the identification of which features of a dataset are relevant to the learning task. It is also widely known and used to improve computation times, reduce computation requirements, and to decrease the impact of the curse of dimensionality and enhancing the generalization rates of classifiers. In data streams, classifiers shall benefit from all the items above, but more importantly, from the fact that the relevant subset of features may drift over time. In this paper, we propose a novel dynamic feature selection method for data streams called Adaptive Boosting for Feature Selection (ABFS). ABFS chains decision stumps and drift detectors, and as a result, identifies which features are relevant to the learning task as the stream progresses with reasonable success. In addition to our proposed algorithm, we bring feature selection-specific metrics from batch learning to streaming scenarios. Next, we evaluate ABFS according to these metrics in both synthetic and real-world scenarios. As a result, ABFS improves the classification rates of different types of learners and eventually enhances computational resources usage.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:journals/eswa/BarddalEGBP19">
  
    <span class="title">Merit-guided dynamic feature selection filter for data streams</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabrı́cio,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Bifet, Albert,
              
            
          
        
      
        
          
            
              
                and Pfahringer, Bernhard
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Expert Syst. Appl.</em>
    
    
      2019
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/merit.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Learning from ephemeral data streams has garnered the interest of both researchers and practitioners towards adaptive learning techniques. Despite the convincing results obtained thus far, most of the current research still overlooks that the relevance of features may change throughout the learning process. Scenarios where features become - or cease to be - relevant to the learning task are called feature drifting data streams, and the identification of which features are relevant becomes even more challenging when the feature space is high-dimensional. To select relevant features during the progress of data streams, we propose a merit-guided and classifier-independent dynamic feature selection algorithm named DynamIc SymmetriCal Uncertainty Selection for Streams (DISCUSS). We evaluate our proposal on both synthetic and real-world datasets and show that DISCUSS can boost kNN and Naive Bayes classifiers’ accuracy rates on high-dimensional data streams, while at the expense of limited processing time and memory space. Finally, the drawbacks of the proposed method are assessed, and possible future works on the topic are also discussed.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2018</h3>
<ol class="bibliography"><li>

<div id="DBLP:conf/esann/GomesBFB18">
  
    <span class="title">Adaptive random forests for data stream regression</span>
    <span class="author">
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Ferreira, Luis Eduardo Boiko,
              
            
          
        
      
        
          
            
              
                and Bifet, Albert
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 26th European Symposium on Artificial Neural Networks, ESANN 2018,
               Bruges, Belgium, April 25-27, 2018</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/arf_regression.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data stream mining is a hot topic in the machine learning community that tackles the problem of learning and updating predictive models as new data becomes available over time. Even though several new methods are proposed every year, most focus on the classification task and overlook the regression task. In this paper, we propose an adaptation to the Adaptive Random Forest so that it can handle regression tasks, namely ARF-Reg. ARF-Reg is empirically evaluated and compared to the state-of-the-art data stream regression algorithms, thus highlighting its applicability in different data stream scenarios.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/ijcnn/FerreiraBEG18">
  
    <span class="title">An Experimental Perspective on Sampling Methods for Imbalanced Learning
               From Financial Databases</span>
    <span class="author">
      
        
          
            
              
                Ferreira, Luis Eduardo Boiko,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabrı́cio,
              
            
          
        
      
        
          
            
              
                and Gomes, Heitor Murilo
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2018 International Joint Conference on Neural Networks, IJCNN 2018,
               Rio de Janeiro, Brazil, July 8-13, 2018</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/experimental.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The financial market is one of the major consumers of data mining techniques, and the main reason is their efficiency to analyze complex data. One important trait shared between most financial applications is class imbalance. Since traditional classification methods assume nearly balanced classes and equal misclassification costs, they usually fail to deal with imbalanced data. However, in financial contexts, problems are usually imbalanced, and instances from the minority class are known for deficits of millions of dollars every year, e.g., credit card frauds, money laundering transactions and so forth. Over the years, several techniques for dealing with class imbalance have been developed, such as sampling techniques and algorithm adaptations. In this study, we analyze how different sampling techniques impact the performance of different classification systems on financial applications. Results show that, for the given datasets, sampling techniques allow the improvement of prediction performance of the minority class while also improving overall classification rates. Nevertheless, their use often deteriorates the performance in predicting the majority class.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/indin/SearaMSB18">
  
    <span class="title">Are fintechs really a hype? A machine learning-based polarity analysis
               of Brazilian posts on social media</span>
    <span class="author">
      
        
          
            
              
                Seara, Marina Ponestke,
              
            
          
        
      
        
          
            
              
                Malucelli, Andreia,
              
            
          
        
      
        
          
            
              
                Santin, Altair Olivo,
              
            
          
        
      
        
          
            
              
                and Barddal, Jean Paul
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 16th IEEE International Conference on Industrial Informatics, INDIN
               2018, Porto, Portugal, July 18-20, 2018</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/fintechs.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Fintechs are technology companies that, in contrast to traditional banks, are engaged in digital solutions for payment, money transfers, and real-time notifications. Taking advantage of digital means of communication, most of the service interactions between fintechs and customers occurs via chats or posts in social media. In this work, our goal is to use machine learning to analyze these posts and identify what are the terms used by customers to express positive, neutral and negative customer experiences. During this analysis, we assess the following questions using data from the 3 biggest fintechs in Brazil: (i) what are the most commented topics on social media regarding fintechs, (ii) what are the words more often used by customers to express positive, negative and neutral reactions to the customer service obtained; and (iii) what kind of machine learning model should a fintech use to automatically identify whether a post is positive, negative or neutral.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/sac/YuanPB18">
  
    <span class="title">Iterative subset selection for feature drifting data streams</span>
    <span class="author">
      
        
          
            
              
                Yuan, Lanqin,
              
            
          
        
      
        
          
            
              
                Pfahringer, Bernhard,
              
            
          
        
      
        
          
            
              
                and Barddal, Jean Paul
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 33rd Annual ACM Symposium on Applied Computing,
               SAC 2018, Pau, France, April 09-13, 2018</em>
    
    
      2018
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/lanqin_sac.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Feature selection has been studied and shown to improve classifier performance in standard batch data mining but is mostly unexplored in data stream mining. Feature selection becomes even more important when the relevant subset of features changes over time, as the underlying concept of a data stream drifts. This specific kind of drift is known as feature drift and requires specific techniques not only to determine which features are the most important but also to take advantage of them. This paper presents a novel method of feature subset selection specialized for dealing with the occurrence of feature drifts called Iterative Subset Selection (ISS), which splits the feature selection process into two stages by first ranking the features, and then iteratively selecting features from the ranking. Applying our feature selection method together with Naive Bayes or k-Nearest Neighbour as a classifier, results in compelling accuracy improvements, compared to prior work.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2017</h3>
<ol class="bibliography"><li>

<div id="DBLP:journals/csur/GomesBEB17">
  
    <span class="title">A Survey on Ensemble Learning for Data Stream Classification</span>
    <span class="author">
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabrı́cio,
              
            
          
        
      
        
          
            
              
                and Bifet, Albert
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>ACM Comput. Surv.</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/survey_ensemble_learning.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Ensemble-based methods are among the most widely used techniques for data stream classification. Their popularity is attributable to their good performance in comparison to strong single learners while being relatively easy to deploy in real-world applications. Ensemble algorithms are especially useful for data stream learning as they can be integrated with drift detection algorithms and incorporate dynamic updates, such as selective removal or addition of classifiers. This work proposes a taxonomy for data stream ensemble learning as derived from reviewing over 60 algorithms. Important aspects such as combination, diversity, and dynamic updates, are thoroughly discussed. Additional contributions include a listing of popular open-source tools and a discussion about current data stream research challenges and how they relate to ensemble learning (big data streams, concept evolution, feature drifts, temporal dependencies, and others).</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:journals/jss/BarddalGEP17">
  
    <span class="title">A survey on feature drift adaptation: Definition, benchmark, challenges
               and future directions</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabrı́cio,
              
            
          
        
      
        
          
            
              
                and Pfahringer, Bernhard
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Journal of Systems and Software</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/survey_feature_drift.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data stream mining is a fast growing research topic due to the ubiquity of data in several real-world problems. Given their ephemeral nature, data stream sources are expected to undergo changes in data distribution, a phenomenon called concept drift. This paper focuses on one specific type of drift that has not yet been thoroughly studied, namely feature drift. Feature drift occurs whenever a subset of features becomes, or ceases to be, relevant to the learning task; thus, learners must detect and adapt to these changes accordingly. We survey existing work on feature drift adaptation with both explicit and implicit approaches. Additionally, we benchmark several algorithms and a naive feature drift detection approach using synthetic and real-world datasets. The results from our experiments indicate the need for future research in this area as even naive approaches produced gains in accuracy while reducing resources usage. Finally, we state current research topics, challenges and future directions for feature drift adaptation.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:journals/ml/GomesBRBEPHA17">
  
    <span class="title">Adaptive random forests for evolving data stream classification</span>
    <span class="author">
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Bifet, Albert,
              
            
          
        
      
        
          
            
              
                Read, Jesse,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabrı́cio,
              
            
          
        
      
        
          
            
              
                Pfharinger, Bernhard,
              
            
          
        
      
        
          
            
              
                Holmes, Geoff,
              
            
          
        
      
        
          
            
              
                and Abdessalem, Talel
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Machine Learning</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/arf.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Random forests is currently one of the most used machine learning algorithms in the non-streaming (batch) setting. This preference is attributable to its high learning performance and low demands with respect to input preparation and hyper-parameter tuning. However, in the challenging context of evolving data streams, there is no random forests algorithm that can be considered state-of-the-art in comparison to bagging and boosting based algorithms. In this work, we present the adaptive random forest (ARF) algorithm for classification of evolving data streams. In contrast to previous attempts of replicating random forests for data stream learning, ARF includes an effective resampling method and adaptive operators that can cope with different types of concept drifts without complex optimizations for different data sets. We present experiments with a parallel implementation of ARF which has no degradation in terms of classification performance in comparison to a serial implementation, since trees and adaptive operators are independent from one another. Finally, we compare ARF with state-of-the-art algorithms in a traditional test-then-train evaluation and a novel delayed labelling evaluation, and show that ARF is accurate and uses a feasible amount of resources.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/ictai/FerreiraBGE17">
  
    <span class="title">Improving Credit Risk Prediction in Online Peer-to-Peer (P2P) Lending
               Using Imbalanced Learning Techniques</span>
    <span class="author">
      
        
          
            
              
                Ferreira, Luis Eduardo Boiko,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabrı́cio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 29th IEEE International Conference on Tools with Artificial Intelligence,
               ICTAI 2017, Boston, MA, USA, November 6-8, 2017</em>
    
    
      2017
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/p2p_resampling.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Peer-to-peer (P2P) lending is a global trend of financial markets that allow individuals to obtain and concede loans without having financial institutions as a strong proxy. As many real-world applications, P2P lending presents an imbalanced characteristic, where the number of creditworthy loan requests is much larger than the number of non-creditworthy ones. In this work, we wrangle a real-world P2P lending data set from Lending Club, containing a large amount of data gathered from 2007 up to 2016. We analyze how supervised classification models and techniques to handle class imbalance impact creditworthiness prediction rates. Ensembles, cost-sensitive and sampling methods are combined and evaluated along logistic regression, decision tree, and bayesian learning schemes. Results show that, in average, sampling techniques outperform ensembles and cost sensitive approaches.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2016</h3>
<ol class="bibliography"><li>

<div id="DBLP:journals/is/BarddalGEB16">
  
    <span class="title">SNCStream+: Extending a high quality true anytime
               data stream clustering algorithm</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabrı́cio,
              
            
          
        
      
        
          
            
              
                and Barthès, Jean-Paul A.
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>Inf. Syst.</em>
    
    
      2016
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/sncstreamplus.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data Stream Clustering is an active area of research which requires efficient algorithms capable of finding and updating clusters incrementally as data arrives. On top of that, due to the inherent evolving nature of data streams, it is expected that algorithms undergo both concept drifts and evolutions, which must be taken into account by the clustering algorithm, allowing incremental clustering updates. In this paper we present the Social Network Clusterer Stream+ (SNCStream+). SNCStream+ tackles the data stream clustering problem as a network formation and evolution problem, where instances and micro-clusters form clusters based on homophily. Our proposal has its parameters analyzed and it is evaluated in a broad set of problems against literature baselines. Results show that SNCStream+ achieves superior clustering quality (CMM), and feasible processing time and memory space usage when compared to the original SNCStream and other proposals of the literature.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/icpr/BarddalGBE16">
  
    <span class="title">A benchmark of classifiers on feature drifting data streams</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Souza Britto Jr., Alceu,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabrı́cio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 23rd International Conference on Pattern Recognition, ICPR 2016,
               Cancún, Mexico, December 4-8, 2016</em>
    
    
      2016
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/benchmark_fd.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The ever increasing data generation confronts both practitioners and researchers on handling massive and sequentially generated amounts of information, the so-called data streams. In this context, a lot of effort has been put on the extraction of useful patterns from streaming scenarios. Learning from data streams embeds a variety of problems, and by far, the most challenging is concept drift, i.e. changes in data distribution. In this paper, we focus on a specific type of drift uncommonly assessed in the literature: feature drifts. Feature drifts occur whenever a subset of features becomes, or ceases to be, relevant to the concept to be learned. We propose and review several feature drifting data stream generators and use them to benchmark state-of-the-art data stream classification algorithms and their combination with drift detectors. Results show that, although drift detectors enable slight quicker recovery to feature drifts, best results are obtained by Hoeffding Adaptive Tree, the only learner that performs dynamic feature selection as streams progress.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/icpr/BarddalGGBE16">
  
    <span class="title">Overcoming feature drifts via dynamic feature weighted k-nearest neighbor
               learning</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Granatyr, Jones,
              
            
          
        
      
        
          
            
              
                Souza Britto Jr., Alceu,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabrı́cio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 23rd International Conference on Pattern Recognition, ICPR 2016,
               Cancún, Mexico, December 4-8, 2016</em>
    
    
      2016
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/overcoming_fd_knn.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Extracting useful knowledge from data streams is problematic, mainly due to changes in their data distribution, a phenomenon named concept drift. Recently, studies have shown that most of existing algorithms for learning from data streams do not encompass techniques for a specific kind of drift: feature drifts. Feature drifts occur when features become, or cease to be, relevant to the learning task. In this paper, we propose an extension to the k-nearest neighbor classifier, so its distances’ computations are weighted according to their current discriminative power. On our proposal, the discriminative power of features is given by entropy, which is swiftly computed over a sliding window. Empirical evidence shows that our approach is able to overcome several existing algorithms in accuracy and feature drift adaptation, while at the expense of bounded processing time and memory space.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/ijcnn/GranatyrBAEG16">
  
    <span class="title">Towards emotion-based reputation guessing learning agents</span>
    <span class="author">
      
        
          
            
              
                Granatyr, Jones,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Almeida, Adriano Weihmayer,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabrı́cio,
              
            
          
        
      
        
          
            
              
                and Santos Granatyr, Adaiane Pereira
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 2016 International Joint Conference on Neural Networks, IJCNN 2016,
               Vancouver, BC, Canada, July 24-29, 2016</em>
    
    
      2016
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/emotion_guessing_agents.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Trust and reputation mechanisms are part of the logical protection of intelligent agents, preventing malicious agents from acting egotistically or with the intention to damage others. Several studies in Psychology, Neurology and Anthropology claim that emotions are part of human’s decision making process. However, there is a lack of understanding about how affective aspects, such as emotions, influence trust or reputation levels of intelligent agents when they are inserted into an information exchange environment, e.g. an evaluation system. In this paper we propose a reputation model that accounts for emotional bounds given by Ekman’s basic emotions and inductive machine learning. Our proposal is evaluated by extracting emotions from texts provided by two online human-fed evaluation systems. Empirical results show significant agent’s utility improvements with p &lt;; .05 when compared to non-emotion-wise proposals, thus, showing the need for future research in this area.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/pkdd/BarddalGEPB16">
  
    <span class="title">On Dynamic Feature Weighting for Feature Drifting Data Streams</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Enembreck, Fabrı́cio,
              
            
          
        
      
        
          
            
              
                Pfahringer, Bernhard,
              
            
          
        
      
        
          
            
              
                and Bifet, Albert
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Machine Learning and Knowledge Discovery in Databases - European Conference,
               ECML PKDD 2016, Riva del Garda, Italy, September 19-23, 2016,
               Proceedings, Part II</em>
    
    
      2016
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/dyn_feature_weighting.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The ubiquity of data streams has been encouraging the development of new incremental and adaptive learning algorithms. Data stream learners must be fast, memory-bounded, but mainly, tailored to adapt to possible changes in the data distribution, a phenomenon named concept drift. Recently, several works have shown the impact of a so far nearly neglected type of drifcccct: feature drifts. Feature drifts occur whenever a subset of features becomes, or ceases to be, relevant to the learning task. In this paper we (i) provide insights into how the relevance of features can be tracked as a stream progresses according to information theoretical Symmetrical Uncertainty; and (ii) how it can be used to boost two learning schemes: Naive Bayesian and k-Nearest Neighbor. Furthermore, we investigate the usage of these two new dynamically weighted learners as prediction models in the leaves of the Hoeffding Adaptive Tree classifier. Results show improvements in accuracy (an average of 10.69 % for k-Nearest Neighbor, 6.23 % for Naive Bayes and 4.42 % for Hoeffding Adaptive Trees) in both synthetic and real-world datasets at the expense of a bounded increase in both memory consumption and processing time.</p>
  </span>
  
</div>
</li></ol>

<h3 class="year">2015</h3>
<ol class="bibliography"><li>

<div id="DBLP:conf/sac/GomesBE15">
  
    <span class="title">Pairwise combination of classifiers for ensemble learning on data
               streams</span>
    <span class="author">
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabrı́cio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 30th Annual ACM Symposium on Applied Computing,
               Salamanca, Spain, April 13-17, 2015</em>
    
    
      2015
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/pairwise_patterns.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>This work presents two different voting strategies for ensemble learning on data streams based on pairwise combination of component classifiers. Despite efforts to build a diverse ensemble, there is always some degree of overlap between component classifiers models. Our voting strategies are aimed at using these overlaps to support ensemble prediction. We hypothesize that by combining pairs of classifiers it is possible to alleviate incorrect individual predictions that would otherwise negatively impact the overall ensemble decision. The first strategy, Pairwise Accuracy (PA), combines the shared accuracy estimation of all possible pairs in the ensemble, while the second strategy, Pairwise Patterns (PP), record patterns of pairwise decisions during training and use these patterns during prediction. We present empirical results comparing ensemble classifiers with their original voting methods and our proposed methods in both real and synthetic datasets, with and without concept drifts. Our analysis indicates that pairwise voting is able to enhance overall performance for PP, especially on real datasets, and that PA is useful whenever there are noticeable differences in accuracy estimates among ensemble members, which is common during concept drifts.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/iceis/SouzaBGBE15">
  
    <span class="title">Applying Ensemble-based Online Learning Techniques on Crime Forecasting</span>
    <span class="author">
      
        
          
            
              
                Souza, Anderson José,
              
            
          
        
      
        
          
            
              
                Borges, André Pinz,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabrı́cio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In ICEIS 2015 - Proceedings of the 17th International Conference on
               Enterprise Information Systems, Volume 1, Barcelona, Spain, 27-30
               April, 2015</em>
    
    
      2015
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/crime_forecasting.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Traditional prediction algorithms assume that the underlying concept is stationary, i.e., no changes are expected to happen during the deployment of an algorithm that would render it obsolete. Although, for many real world scenarios changes in the data distribution, namely concept drifts, are expected to occur due to variations in the hidden context, e.g., new government regulations, climatic changes, or adversary adaptation. In this paper, we analyze the problem of predicting the most susceptible types of victims of crimes occurred in a large city of Brazil. It is expected that criminals change their victims’ types to counter police methods and vice-versa. Therefore, the challenge is to obtain a model capable of adapting rapidly to the current preferred criminal victims, such that police resources can be allocated accordingly. In this type of problem the most appropriate learning models are provided by data stream mining, since the learning algorithms from this domain assume that concept drifts may occur over time, and are ready to adapt to them. In this paper we apply ensemble-based data stream methods, since they provide good accuracy and the ability to adapt to concept drifts. Results show that the application of these ensemble-based algorithms (Leveraging Bagging, SFNClassifier, ADWIN Bagging and Online Bagging) reach feasible accuracy for this task.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/iconip/BarddalGE15">
  
    <span class="title">Analyzing the Impact of Feature Drifts in Streaming Learning</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabrı́cio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Neural Information Processing - 22nd International Conference, ICONIP
               2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part I</em>
    
    
      2015
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/analyzing_feature_drifts.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Learning from data streams requires efficient algorithms capable of deriving a model accordingly to the arrival of new instances. Data streams are by definition unbounded sequences of data that are possibly non stationary, i.e. they may undergo changes in data distribution, phenomenon named concept drift. Concept drifts force streaming learning algorithms to detect and adapt to such changes in order to present feasible accuracy throughout time. Nonetheless, most of works presented in the literature do not account for a specific kind of drifts: feature drifts. Feature drifts occur whenever the relevance of an arbitrary attribute changes through time, also impacting the concept to be learned. In this paper we (i) verify the occurrence of feature drift in a publicly available dataset, (ii) present a synthetic data stream generator capable of performing feature drifts and (iii) analyze the impact of this type of drift in stream learning algorithms, enlightening that there is room and the need for dynamic feature selection strategies for data streams.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/iconip/GomesCZBM15">
  
    <span class="title">On the Discovery of Time Distance Constrained Temporal Association
               Rules</span>
    <span class="author">
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                Carvalho, Deborah Ribeiro,
              
            
          
        
      
        
          
            
              
                Zubieta, Lourdes,
              
            
          
        
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                and Malucelli, Andreia
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Neural Information Processing - 22nd International Conference, ICONIP
               2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part II</em>
    
    
      2015
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/temporalassociatedrules.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>The increased use of data mining algorithms reflects the need for automatic extraction of knowledge from large volumes of data. This work presents a temporal data mining algorithm that discovers frequent Association Rules from timestamped data. These rules are named Cause-Effect Rules, each represented by a multiset of unordered events (Cause) followed by a singleton event (Effect). Also, a Cause-Effect Rule is valid within an specific constraint that defines the minimum and maximum time distance between its Cause and Effect. Our algorithm was tested on a data set from two hospital emergency departments in Sherbrooke, QC, Canada.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/iconip/BarddalGE15a">
  
    <span class="title">A Complex Network-Based Anytime Data Stream Clustering Algorithm</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabrı́cio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Neural Information Processing - 22nd International Conference, ICONIP
               2015, Istanbul, Turkey, November 9-12, 2015, Proceedings, Part I</em>
    
    
      2015
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/cndenstream.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data stream mining is an active area of research that poses challenging research problems. In the latter years, a variety of data stream clustering algorithms have been proposed to perform unsupervised learning using a two-step framework. Additionally, dealing with non-stationary, unbounded data streams requires the development of algorithms capable of performing fast and incremental clustering addressing time and memory limitations without jeopardizing clustering quality. In this paper we present CNDenStream, a one-step data stream clustering algorithm capable of finding non-hyper-spherical clusters which, in opposition to other data stream clustering algorithms, is able to maintain updated clusters after the arrival of each instance by using a complex network construction and evolution model based on homophily. Empirical studies show that CNDenStream is able to surpass other algorithms in clustering quality and requires a feasible amount of resources when compared to other algorithms presented in the literature.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/ictai/BarddalGE15">
  
    <span class="title">A Survey on Feature Drift Adaptation</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabrı́cio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In 27th IEEE International Conference on Tools with Artificial Intelligence,
               ICTAI 2015, Vietri sul Mare, Italy, November 9-11, 2015</em>
    
    
      2015
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/survey_fd.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data stream mining is a fast growing research topic due to the ubiquity of data in several real-world problems. Given their ephemeral nature, data stream sources are expected to undergo changes in data distribution, a phenomenon called concept drift. This paper focuses on one specific type of drift that has not yet been thoroughly studied, namely feature drift. Feature drift occurs whenever a subset of features becomes, or ceases to be, relevant to the learning task; thus, learners must detect and adapt to these changes accordingly. We survey existing work on feature drift adaptation with both explicit and implicit approaches. Additionally, we benchmark several algorithms and a naive feature drift detection approach using synthetic and real-world datasets. The results from our experiments indicate the need for future research in this area as even naive approaches produced gains in accuracy while reducing resources usage. Finally, we state current research topics, challenges and future directions for feature drift adaptation.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:conf/sac/BarddalGE15">
  
    <span class="title">SNCStream: a social network-based data stream clustering algorithm</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabrı́cio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>In Proceedings of the 30th Annual ACM Symposium on Applied Computing,
               Salamanca, Spain, April 13-17, 2015</em>
    
    
      2015
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/sncstream.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Data Stream Clustering is an active area of research which requires efficient algorithms capable of finding and updating clusters incrementally. On top of that, due to the inherent evolving nature of data streams, it is expected that these algorithms manage to quickly adapt to both concept drifts and the appearance and disappearance of clusters. Nevertheless, many of the developed two-step algorithms are only capable of finding hyper-spherical clusters and are highly dependant on parametrization. In this paper we introduce SNCStream, a one-step online clustering algorithm based on Social Networks Theory, which uses homophily to find non-hyper-spherical clusters. Our empirical studies show that SNCStream is able to surpass density-based algorithms in cluster quality and requires feasible amount of resources (time and memory) when compared to other algorithms.</p>
  </span>
  
</div>
</li>
<li>

<div id="DBLP:journals/ijncr/BarddalGE15">
  
    <span class="title">Advances on Concept Drift Detection in Regression Tasks Using Social
               Networks Theory</span>
    <span class="author">
      
        
          
            
              
                Barddal, Jean Paul,
              
            
          
        
      
        
          
            
              
                Gomes, Heitor Murilo,
              
            
          
        
      
        
          
            
              
                and Enembreck, Fabrı́cio
              
            
          
        
      
    </span>

    <span class="periodical">
    
      <em>IJNCR</em>
    
    
      2015
    
    </span>
  

  <span class="links">
  
    [<a class="abstract">Abs</a>]
  
  
  
  
    [<a href="https://jpbarddal.github.io//assets/pdf/ijncr.pdf" target="_blank">PDF</a>]
  
  
  
  
  
  </span>

  <!-- Hidden abstract block -->
  
  <span class="abstract hidden">
    <p>Mining data streams is one of the main studies in machine learning area due to its application in many knowledge areas. One of the major challenges on mining data streams is concept drift, which requires the learner to discard the current concept and adapt to a new one. Ensemble-based drift detection algorithms have been used successfully to the classification task but usually maintain a fixed size ensemble of learners running the risk of needlessly spending processing time and memory. In this paper the authors present improvements to the Scale-free Network Regressor (SFNR), a dynamic ensemble-based method for regression that employs social networks theory. In order to detect concept drifts SFNR uses the Adaptive Window (ADWIN) algorithm. Results show improvements in accuracy, especially in concept drift situations and better performance compared to other state-of-the-art algorithms in both real and synthetic data.</p>
  </span>
  
</div>
</li></ol>


  </article>

  

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2022 Jean Paul Barddal.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<!-- <script src="https://jpbarddal.github.io//assets/js/common.js"></script> -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>




<!-- Include custom icon fonts -->
<!-- <link rel="stylesheet" href="https://jpbarddal.github.io//assets/css/fontawesome-all.min.css"> -->
<!-- <link rel="stylesheet" href="https://jpbarddal.github.io//assets/css/academicons.min.css"> -->

<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">

<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-XXXXXXXXX', 'auto');
ga('send', 'pageview');
</script>


  </body>

</html>
